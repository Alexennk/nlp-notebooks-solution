{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0b06ba3f-3c98-4fd7-948d-362d3260fc5d","cell_type":"markdown","source":"# Введение в NLP, часть 2\n","metadata":{"id":"0b06ba3f-3c98-4fd7-948d-362d3260fc5d"}},{"id":"09171b28","cell_type":"code","source":"!pip install -U pip\n!pip install transformers==4.45.2 # в этой версии нет проблем с предупреждением \n# \"trainer.tokenizer is now deprecated. you should use trainer.processing_class instead.\"\n# в других версиях оно неизбежно появляется и мешает при обучении\n!pip install datasets torch seqeval evaluate","metadata":{"id":"09171b28","trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"id":"a0f3154e","cell_type":"markdown","source":"\n## NER c BERT (25 баллов)\n\n1. Взять датасет из предыдущего ДЗ и обучить на нём BERT.\n2. Обучить BERT на подготовленном датасете\n3. Оценить результат, сравнить с моделью из первого ДЗ","metadata":{"id":"a0f3154e"}},{"id":"27a696ec-f1af-4779-bb81-a4aa644fddfd","cell_type":"markdown","source":"### Подготовка данных (5 баллов)\n\nПодумать о:\n1) Как subword токенизация повлияет на BIO раззметку?\n2) Что делать с `[CLS]` и `[SEP]` токенами? (Проверьте что использует `DataCollatorForTokenClassification`)\n\n> Hint! Токенайзер умеет работать с предразделёнными на \"слова\" текстами","metadata":{"id":"27a696ec-f1af-4779-bb81-a4aa644fddfd"}},{"id":"fc5e633a-23c1-4b54-9529-c1f32cb5ff89","cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer\n\n\nBASE_NER_MODEL = \"bert-base-cased\"\nbert_tokenizer = AutoTokenizer.from_pretrained(BASE_NER_MODEL)\n\nconll2003 = load_dataset(\"conll2003\")\nconll2003","metadata":{"id":"fc5e633a-23c1-4b54-9529-c1f32cb5ff89","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:39:47.156849Z","iopub.execute_input":"2025-02-03T18:39:47.157227Z","iopub.status.idle":"2025-02-03T18:40:09.307280Z","shell.execute_reply.started":"2025-02-03T18:39:47.157189Z","shell.execute_reply":"2025-02-03T18:40:09.306602Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea9cf016d03347b5ac0d14a6174c2a14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af699000b6f454da882a59eb42ddba8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff4a4b442e741a583c818561f270eb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd819746f7f9421e8bd5fae9e57c4a64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"376c50e5b64d48058e6c74a486b208b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3e2e9f4f304d7fb3cb04598a16efe6"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  н\nThe repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7abe08297924491aa39a4c72f72f00d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c18fa58eeeb4ae7bc036e6b53be68e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acdc821df0b4491284296023e0a7bd92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc38afc4cbbe45b7ba47669932b50eb9"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":2},{"id":"92a1ac5b-0722-4387-a885-80b927fbc10a","cell_type":"code","source":"example = conll2003[\"train\"][100]\nexample","metadata":{"id":"92a1ac5b-0722-4387-a885-80b927fbc10a","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:40:20.108771Z","iopub.execute_input":"2025-02-03T18:40:20.109097Z","iopub.status.idle":"2025-02-03T18:40:20.116657Z","shell.execute_reply.started":"2025-02-03T18:40:20.109038Z","shell.execute_reply":"2025-02-03T18:40:20.115650Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'id': '100',\n 'tokens': ['Rabinovich',\n  'is',\n  'winding',\n  'up',\n  'his',\n  'term',\n  'as',\n  'ambassador',\n  '.'],\n 'pos_tags': [21, 42, 39, 33, 29, 21, 15, 21, 7],\n 'chunk_tags': [11, 21, 22, 15, 11, 12, 13, 11, 0],\n 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}],"execution_count":3},{"id":"2c070226-e70f-4df1-b770-f403a19ef205","cell_type":"markdown","source":"* tokens - исходные токены, для которых была сделана NER-разметка\n* ner_tags - векторизированные метки NER-тэгов\n* pos_tags - разметка частей речи, которую мы игнорируем\n* chunk_tags - разметка чанков, которую мы игнорируем\n\nОбратите внимание, что количество токенов может превышать количество исходных лейблов:","metadata":{"id":"2c070226-e70f-4df1-b770-f403a19ef205"}},{"id":"98d060e0-8b58-4c58-a8b6-9ecd91e31777","cell_type":"code","source":"bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens()","metadata":{"id":"98d060e0-8b58-4c58-a8b6-9ecd91e31777","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:40:28.963872Z","iopub.execute_input":"2025-02-03T18:40:28.964252Z","iopub.status.idle":"2025-02-03T18:40:28.970081Z","shell.execute_reply.started":"2025-02-03T18:40:28.964222Z","shell.execute_reply":"2025-02-03T18:40:28.969415Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'Ra',\n '##bino',\n '##vich',\n 'is',\n 'winding',\n 'up',\n 'his',\n 'term',\n 'as',\n 'ambassador',\n '.',\n '[SEP]']"},"metadata":{}}],"execution_count":4},{"id":"bdb99e70-85e2-438f-8c68-e15a6701ccfa","cell_type":"markdown","source":"Значение тэга в ner_tags отображается в метку NER:","metadata":{"id":"bdb99e70-85e2-438f-8c68-e15a6701ccfa"}},{"id":"1b8fce68-13e8-4093-a147-15ae865ac73a","cell_type":"code","source":"print(\"NER TAGS\", example[\"ner_tags\"])\nprint(conll2003[\"train\"].features[\"ner_tags\"].feature)","metadata":{"id":"1b8fce68-13e8-4093-a147-15ae865ac73a","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:40:42.197437Z","iopub.execute_input":"2025-02-03T18:40:42.197722Z","iopub.status.idle":"2025-02-03T18:40:42.202696Z","shell.execute_reply.started":"2025-02-03T18:40:42.197701Z","shell.execute_reply":"2025-02-03T18:40:42.201743Z"}},"outputs":[{"name":"stdout","text":"NER TAGS [1, 0, 0, 0, 0, 0, 0, 0, 0]\nClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None)\n","output_type":"stream"}],"execution_count":5},{"id":"ea7e9ac1-89fa-448f-9033-37074fb3d692","cell_type":"code","source":"print(\"Оригинальные токены\")\nprint(example[\"tokens\"])\nprint(\"Векторизированные NER метки токенов\")\nprint(example[\"ner_tags\"])\ntags_str = []\nfeatures = conll2003[\"train\"].features[\"ner_tags\"].feature\nfor tag in example[\"ner_tags\"]:\n    tags_str.append(features.int2str(tag))\nprint(\"Текстовые NER метки токенов\")\nprint(tags_str)\nprint(\"Токены после работы токенайзера BERT\")\nprint(bert_tokenizer(example[\"tokens\"], is_split_into_words=True).tokens())","metadata":{"id":"ea7e9ac1-89fa-448f-9033-37074fb3d692","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:40:45.736851Z","iopub.execute_input":"2025-02-03T18:40:45.737207Z","iopub.status.idle":"2025-02-03T18:40:45.745397Z","shell.execute_reply.started":"2025-02-03T18:40:45.737177Z","shell.execute_reply":"2025-02-03T18:40:45.744573Z"}},"outputs":[{"name":"stdout","text":"Оригинальные токены\n['Rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']\nВекторизированные NER метки токенов\n[1, 0, 0, 0, 0, 0, 0, 0, 0]\nТекстовые NER метки токенов\n['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\nТокены после работы токенайзера BERT\n['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']\n","output_type":"stream"}],"execution_count":6},{"id":"d1ce9764-c763-44c2-a915-b938b27a9866","cell_type":"markdown","source":"Вспомним немного, как работают метки в задаче мер в кодировке BIO. В данной задаче у нас есть 4 типа именованных сущностей:\n* PER - персона\n* ORG - организация\n* LOC - локация\n* MISC - другое\n* O - отсутствие именованной сущности\n\nУ каждого типа именованных 2 префикса:\n* `B-` - beginning, т.е. начало именованной сущности.\n* `I-` - inside, т.е. продолжение ранее начатой именованной сущностью.\n\nВ исходной токенизации\n\n`['Rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']`\nметки выглядят как\n\n`['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']`\nт.е. `Rabinovich` является персоной. На следующем токене именованная сущность заканчивается, т.к. у него метка `O`.\n\nПосле токенизации BERT наш сэмпл превращается в следующие токены:\n\n`['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']`\nОбратим внимание, что один токен `Rabinovich` с меткой `B-PER` был разбит токенизатором берта на 3 токена: `'Ra', '##bino', '##vich'`. Им нужно поставить в соответствие 3 метки: `B-PER, I-PER, I-PER`, т.е. мы разбиваем метку исходного токена на новые токены.\n\nТакже обратим внимание на первый и последний токен - это спецстокены BERT означающие начало и конец текста. Им можно дать метки `O`, т.к. они не являются частью исходного текста, но мы будем давать им особое векторизированное значение -100. В [документации pytroch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) у кроссэнтропийной функции потерь это дефолтное значение `ignore_index`, т.е. метки, которую мы будем игнорировать. Библиотека transformers также использует это значение. Таким образом на токенах, у которых стоит -100 в качестве векторизированного NER-тэга, не будет происходить обучение, они будут проигнорированы.\n\n\n","metadata":{"id":"d1ce9764-c763-44c2-a915-b938b27a9866"}},{"id":"1c6ac7b9-d65f-4e09-8165-de5442a6ab6e","cell_type":"markdown","source":"Напишите функцию `preprocess_ner_dataset`, которая разворачивает `ner_tags` для слов в тэги для BERT-токенов и готовит остальные данные для обучения (можно разделить на две функции или написать всё в одной). В резултате применения `conll2003.map(preprocess_ner_dataset)`, в каждом примере:\n1. Добавляется токенизированный вход (`input_ids`, `token_type_ids` и `attention_mask`). При конструировании этих векторов вручную нужно проставить `attention_mask` полностью единицами, т.к. в паддинги в сэмплах появляются только в рамках батчей, а `token_type_ids` полностью нулями.\n2. `ner_tags` разворачивается в `labels` для входных токенов\n\nЧто можно использовать:\n* у объекта `conll2003[\"train\"].features[\"ner_tags\"].feature` есть методы `int2str` и `str2int` для превращение векторизованного NER-тэга в строковый вид и обратно\n* Спецтокенам BERT нужно поставить значение -100\n* вызов `bert_tokenizer(bert_tokenizer(example[\"tokens\"], is_split_into_words=True)` возвращает вам input_ids, attention_mask, token_type_ids\n* Вызов `bert_tokenizer(example[\"tokens\"], is_split_into_words=True, return_offsets_mapping=True))` возвращает дополнительно offset_mapping, позиции новых токенов в оригинальном тексте\n* `bert_tokenizer.vocab` - для превращения токенов в их индексы в словаре\n* `bert_tokenizer.tokenize` - разбитие текста (в том числе и исходных токенов) на токены BERT\n\nВаша задача:\n1. Создать новый dict, в котором будут input_ids, attention_mask, token_type_ids\n2. Добавить в него labels - векторизированные NER-тэги, которые будут разбиты в соответствии с токенизацией BERT. Для этого можно можно разбить каждый токен отдельно и размножить его метки. Альтернативно можно использовать информацию об оффсетах токенов BERT, чтобы понять, частью какого исходного токена и какой исходной метки является данный BERT-токен.","metadata":{"id":"1c6ac7b9-d65f-4e09-8165-de5442a6ab6e"}},{"id":"8e3fa5fa-e016-491d-914e-e1ba2f23d8a4","cell_type":"code","source":"# получение NER-тегов для subword токенов\ndef form_labels(example):\n    features = conll2003[\"train\"].features[\"ner_tags\"].feature\n    tags_str = []\n    for tag in example[\"ner_tags\"]:\n        tags_str.append(features.int2str(tag)) # текстовые представления NER-тегов для слов\n    labels = []\n    for i, word in enumerate(example['tokens']): # получение тэгов для токенов, на которые разбивается каждое отдельное слово\n        tag = tags_str[i]\n        bert_tokens = bert_tokenizer(word).tokens()[1:-1]\n        if tag == 'O' or tag[0] == 'I':\n            for _ in range(len(bert_tokens)):\n                labels.append(features.str2int(tag))\n        else:\n            for j in range(len(bert_tokens)):\n                labels.append(features.str2int(tag) if j == 0 else features.str2int('I' + tag[1:]))\n    return [-100] + labels + [-100]\n\n# основная функция\ndef preprocess_ner_dataset(example):\n    new_dict = {}\n    input_ids = bert_tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n    new_dict['input_ids'] = input_ids\n    len_tokenized = len(input_ids)\n    \n    new_dict['token_type_ids'] = [0] * len_tokenized\n    new_dict['attention_mask'] = [1] * len_tokenized\n    new_dict['labels'] = form_labels(example)\n    return new_dict","metadata":{"id":"8e3fa5fa-e016-491d-914e-e1ba2f23d8a4","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:42:26.579835Z","iopub.execute_input":"2025-02-03T18:42:26.580225Z","iopub.status.idle":"2025-02-03T18:42:26.587448Z","shell.execute_reply.started":"2025-02-03T18:42:26.580190Z","shell.execute_reply":"2025-02-03T18:42:26.586434Z"}},"outputs":[],"execution_count":7},{"id":"19ecaf00-45f6-4eb9-a921-31c4756edfcd","cell_type":"markdown","source":"Пример получившегося выхода:\n```python\n>>> preprocessed_ner_dataset[\"train\"][100]\n{'id': '100',\n 'tokens': ['Rabinovich',\n  'is',\n  'winding',\n  'up',\n  'his',\n  'term',\n  'as',\n  'ambassador',\n  '.'],\n 'pos_tags': [21, 42, 39, 33, 29, 21, 15, 21, 7],\n 'chunk_tags': [11, 21, 22, 15, 11, 12, 13, 11, 0],\n 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 0, 0],\n 'input_ids': [101,\n  16890,\n  25473,\n  11690,\n  1110,\n  14042,\n  1146,\n  1117,\n  1858,\n  1112,\n  9088,\n  119,\n  102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n 'labels': [-100, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, -100]}\n```\n\n### Тесты","metadata":{"id":"19ecaf00-45f6-4eb9-a921-31c4756edfcd"}},{"id":"c378788f-38b9-4b80-9a9a-89ab561b5933","cell_type":"code","source":"processed_example = preprocess_ner_dataset(example)\nrequired_keys = [\"input_ids\", \"labels\", \"attention_mask\", \"token_type_ids\"]\nfor k in required_keys:\n    assert k in processed_example, f\"Отсутствует поле {k}\"\n\nrequired_keys_set = set(required_keys)\nfor k in processed_example.keys():\n    assert k in required_keys_set, f\"В примере лишнее поле {k}\"","metadata":{"id":"c378788f-38b9-4b80-9a9a-89ab561b5933","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:44:37.194171Z","iopub.execute_input":"2025-02-03T18:44:37.194453Z","iopub.status.idle":"2025-02-03T18:44:37.200421Z","shell.execute_reply.started":"2025-02-03T18:44:37.194433Z","shell.execute_reply":"2025-02-03T18:44:37.199768Z"}},"outputs":[],"execution_count":9},{"id":"79adc4dd-791f-4f8d-8799-8904907f78d3","cell_type":"code","source":"from tqdm import tqdm\nfor idx, example in tqdm(enumerate(conll2003[\"train\"])):\n    input_ids_real = bert_tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n    input_ids_ours = preprocess_ner_dataset(example)[\"input_ids\"]\n    assert input_ids_real == input_ids_ours, f\"Ошибка токенизации на примере {idx}\"\n    if idx >= 100:\n        break\nprint(\"Токенизация верна!\")","metadata":{"id":"79adc4dd-791f-4f8d-8799-8904907f78d3","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:44:40.379794Z","iopub.execute_input":"2025-02-03T18:44:40.380117Z","iopub.status.idle":"2025-02-03T18:44:40.533425Z","shell.execute_reply.started":"2025-02-03T18:44:40.380092Z","shell.execute_reply":"2025-02-03T18:44:40.532589Z"}},"outputs":[{"name":"stderr","text":"100it [00:00, 685.91it/s]","output_type":"stream"},{"name":"stdout","text":"Токенизация верна!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"id":"409ee982-3f01-4519-abd6-20f3f6050562","cell_type":"code","source":"example = conll2003[\"train\"][100]\nprocessed_example = preprocess_ner_dataset(example)\n\nassert processed_example[\"labels\"][0] == -100\nassert processed_example[\"labels\"][-1] == -100\nner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\nassert ner_tags == ['B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']","metadata":{"id":"409ee982-3f01-4519-abd6-20f3f6050562","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:44:45.346972Z","iopub.execute_input":"2025-02-03T18:44:45.347348Z","iopub.status.idle":"2025-02-03T18:44:45.353946Z","shell.execute_reply.started":"2025-02-03T18:44:45.347320Z","shell.execute_reply":"2025-02-03T18:44:45.353226Z"}},"outputs":[],"execution_count":11},{"id":"2e61ee0b-a4dd-4fba-8e12-a89d57886d09","cell_type":"code","source":"example = conll2003[\"train\"][200]\nprocessed_example = preprocess_ner_dataset(example)\n\nassert processed_example[\"labels\"][0] == -100\nassert processed_example[\"labels\"][-1] == -100\nner_tags = [features.int2str(i) for i in processed_example[\"labels\"][1:-1]]\nassert ner_tags == ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG']","metadata":{"id":"2e61ee0b-a4dd-4fba-8e12-a89d57886d09","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:44:48.279219Z","iopub.execute_input":"2025-02-03T18:44:48.279505Z","iopub.status.idle":"2025-02-03T18:44:48.285262Z","shell.execute_reply.started":"2025-02-03T18:44:48.279486Z","shell.execute_reply":"2025-02-03T18:44:48.284435Z"}},"outputs":[],"execution_count":12},{"id":"257320fd-9a53-4bfe-a7fd-8199e05d4f83","cell_type":"markdown","source":"Применим нашу функцию к всему датасету:","metadata":{"id":"257320fd-9a53-4bfe-a7fd-8199e05d4f83"}},{"id":"3f871318-7c1b-4a89-b3ae-ef131c9bf95e","cell_type":"code","source":"preprocessed_ner_dataset = conll2003.map(preprocess_ner_dataset)","metadata":{"id":"3f871318-7c1b-4a89-b3ae-ef131c9bf95e","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:50:28.074671Z","iopub.execute_input":"2025-02-03T18:50:28.074978Z","iopub.status.idle":"2025-02-03T18:50:54.062917Z","shell.execute_reply.started":"2025-02-03T18:50:28.074957Z","shell.execute_reply":"2025-02-03T18:50:54.061930Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f14a55d205014cb88d26996c04541041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7db53b2e9b449beb490c7e130c07acc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f75b1892e1b43f398eb7dd89bef0c0d"}},"metadata":{}}],"execution_count":13},{"id":"f57e0a33-dea2-49d5-8b53-f54cd2048454","cell_type":"markdown","source":"Подготовим `data_collator`. Это особый класс, который будет заниматься батчеванием сэмплов для обучения. Он добавит паддинги во все необходимые поля.","metadata":{"id":"f57e0a33-dea2-49d5-8b53-f54cd2048454"}},{"id":"a20511a1-d222-4034-b099-9dfdd02ed81b","cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=bert_tokenizer)","metadata":{"id":"a20511a1-d222-4034-b099-9dfdd02ed81b","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T18:52:08.851022Z","iopub.execute_input":"2025-02-03T18:52:08.851671Z","iopub.status.idle":"2025-02-03T18:52:08.855354Z","shell.execute_reply.started":"2025-02-03T18:52:08.851640Z","shell.execute_reply":"2025-02-03T18:52:08.854455Z"}},"outputs":[],"execution_count":15},{"id":"a0c7c640-ac2b-4388-81b6-9f21c8c2ec2d","cell_type":"markdown","source":"### Подготовка модели (5 баллов)\n\nДва возможных пути на этой стадии:\n1. Взять [готовый класс](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelfortokenclassification) модели для классификации токенов. (Этот вариант настоятельно рекомендуется)\n2) Взять модель как фича экстрактор ([AutoModel](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodel)) и самостоятельно добавить классификационную голову. Вдохновиться можно по [ссылке](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py#L1847-L1860). Дополнительных баллов второй вариант не принесёт.\n\nРезультатом должна быть модель, которая для каждого токена возвращает логиты/вероятности для `conll2003[\"train\"].features[\"ner_tags\"].feature.num_classes` классов.\n\n> Если выберете вариант номер один, опишите как он работает - как из токена получается его `ner_tag`.","metadata":{"id":"a0c7c640-ac2b-4388-81b6-9f21c8c2ec2d"}},{"id":"331cd38a-3501-4f41-9193-8cf6579ad80e","cell_type":"code","source":"from transformers import AutoModelForTokenClassification, BertConfig\n\n\nconfig = BertConfig.from_pretrained(BASE_NER_MODEL)\nconfig.num_labels = features.num_classes\nmodel = AutoModelForTokenClassification.from_config(config) ","metadata":{"id":"331cd38a-3501-4f41-9193-8cf6579ad80e","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:26:47.618107Z","iopub.execute_input":"2025-02-03T19:26:47.618431Z","iopub.status.idle":"2025-02-03T19:26:49.289803Z","shell.execute_reply.started":"2025-02-03T19:26:47.618406Z","shell.execute_reply":"2025-02-03T19:26:49.289131Z"}},"outputs":[],"execution_count":40},{"id":"73eaa2ce-0f56-4b8f-8829-ff9edffa0d34","cell_type":"markdown","source":"### Подготовим Метрику (5 баллов)\n\nДополните функцию, используя `metrics_calculator`, чтобы она возвращала `accuracy`, `precision`, `recall` и `f-меру`. `eval_predictions` - это кортеж из логитов токен классификатора и `labels`, которые мы подготовили с помощью `preprocess_ner_dataset`. Нужно:\n1. Преобразовать логиты в предсказанные лейблы. Учтите, что для специальных токенов лейблов нет\n2. Посчитать метрики с помощью `metrics_calculator`\n3. Упаковать резултат в `dict`, в котором ключём будет название метрики, а значением - значение метрики\n\nВ logits будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности, число меток\\], содержащий предсказания модели\n\nВ target_labels будет лежать тензор размерности \\[размер eval датасета, максимальная длина последовательности\\], содержащий метки из валидационной выборки.\n\nПримеры функции calculate_metrics можно посмотреть в [документации](https://huggingface.co/docs/evaluate/en/transformers_integrations)","metadata":{"id":"73eaa2ce-0f56-4b8f-8829-ff9edffa0d34"}},{"id":"316c631d","cell_type":"code","source":"import numpy as np\nimport evaluate\n\nmetrics_calculator = evaluate.load(\"seqeval\")\n\ndef calculate_metrics(eval_predictions):\n    logits, target_labels = eval_predictions\n    predictions = np.argmax(logits, axis=-1)\n    \n    true_labels = []\n    pred_labels = []\n    \n    for target_seq, pred_seq in zip(target_labels, predictions): # в цикле отбираются предсказания для неспециальных токенов\n        true_seq = []\n        pred_seq_filtered = []\n        \n        for true_label, pred_label in zip(target_seq, pred_seq):\n            if true_label != -100:\n                true_seq.append(features.int2str(int(true_label))) # с np.int64 была ошибка, поэтому явно привел к int :/\n                pred_seq_filtered.append(features.int2str(int(pred_label)))\n        \n        true_labels.append(true_seq)\n        pred_labels.append(pred_seq_filtered)\n    \n    metrics = metrics_calculator.compute(predictions=pred_labels, references=true_labels)\n    \n    return {\n        \"accuracy\": metrics[\"overall_accuracy\"],\n        \"precision\": metrics[\"overall_precision\"],\n        \"recall\": metrics[\"overall_recall\"],\n        \"f1\": metrics[\"overall_f1\"]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:26:19.298853Z","iopub.execute_input":"2025-02-03T19:26:19.299182Z","iopub.status.idle":"2025-02-03T19:26:19.836105Z","shell.execute_reply.started":"2025-02-03T19:26:19.299156Z","shell.execute_reply":"2025-02-03T19:26:19.835439Z"}},"outputs":[],"execution_count":37},{"id":"c44528ae-e63a-4561-b707-a891f8dcf75f","cell_type":"markdown","source":"### Обучение (5 баллов)\n\nДва возможных пути на этой стадии:\n\n1. Использовать [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) класс из `transformers`\n2. Написать свой training loop. Дополнительных баллов на этом пути нет.\n\nОпишем подробнее первый путь, т.к. он настоятельно рекомендуется.\n\nНужно создать класс Trainer и TrainingArguments.\nВ [TrainingArguments](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments) нужно как минимум следующие поля:\n* save_strategy, eval_strategy\n* metric_for_best_model (исходя из calculate_metrics), greater_is_better\n* learning_rate (возьмите 2e-5)\n* num_train_epochs\n* per_device_train_batch_size, per_device_eval_batch_size\n\nВ класс Trainer нужно передать:\n* model\n* в args нужно передать заполненные TrainingArguments\n* train_dataset, eval_dataset\n* tokenizer\n* compute_metrics\n\nПосле чего запустить `trainer.train()`","metadata":{"id":"c44528ae-e63a-4561-b707-a891f8dcf75f"}},{"id":"b83fb986-e918-46f2-89f4-74e74af45ecc","cell_type":"code","source":"import torch\n\nprint(torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:10:50.794411Z","iopub.execute_input":"2025-02-03T19:10:50.794763Z","iopub.status.idle":"2025-02-03T19:10:50.799415Z","shell.execute_reply.started":"2025-02-03T19:10:50.794732Z","shell.execute_reply":"2025-02-03T19:10:50.798521Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":32},{"id":"430fcb64-417c-44de-a382-cadc15a11c12","cell_type":"code","source":"from tqdm.notebook import tqdm\ntqdm.pandas() # чтобы наверняка отображался прогресс при обучении","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:10:52.692381Z","iopub.execute_input":"2025-02-03T19:10:52.692671Z","iopub.status.idle":"2025-02-03T19:10:52.697410Z","shell.execute_reply.started":"2025-02-03T19:10:52.692648Z","shell.execute_reply":"2025-02-03T19:10:52.696587Z"}},"outputs":[],"execution_count":33},{"id":"6542fdb7-3f52-40f3-816f-c405ea0ee0d7","cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    save_strategy=\"epoch\",\n    eval_strategy=\"steps\",\n    eval_steps=250,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n    learning_rate=7e-5,\n    warmup_steps = 300,\n    weight_decay=0.01,  # Regularization\n    num_train_epochs=15,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    eval_accumulation_steps=10,\n    gradient_accumulation_steps=4,\n    save_total_limit=2,\n    report_to=\"none\",  # Disable logging to W&B\n    run_name=\"ner_experiment\",  # Optional: Set a custom run name\n    fp16=True,\n)","metadata":{"id":"a3593874-6c27-464d-a424-603f7c4ab4a0","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:27:07.946111Z","iopub.execute_input":"2025-02-03T19:27:07.946419Z","iopub.status.idle":"2025-02-03T19:27:07.975566Z","shell.execute_reply.started":"2025-02-03T19:27:07.946395Z","shell.execute_reply":"2025-02-03T19:27:07.974697Z"}},"outputs":[],"execution_count":41},{"id":"723099fc-acc6-4064-89d9-4b62c75dc203","cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=preprocessed_ner_dataset[\"train\"],\n    eval_dataset=preprocessed_ner_dataset[\"validation\"],\n    tokenizer=bert_tokenizer,\n    data_collator=data_collator,\n    compute_metrics=calculate_metrics,\n)\n\ntrainer.train()","metadata":{"id":"a3593874-6c27-464d-a424-603f7c4ab4a0","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:27:11.975734Z","iopub.execute_input":"2025-02-03T19:27:11.976021Z","iopub.status.idle":"2025-02-03T19:46:17.965096Z","shell.execute_reply.started":"2025-02-03T19:27:11.976000Z","shell.execute_reply":"2025-02-03T19:46:17.964396Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1635' max='1635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1635/1635 19:04, Epoch 14/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>No log</td>\n      <td>0.420419</td>\n      <td>0.874065</td>\n      <td>0.366264</td>\n      <td>0.469202</td>\n      <td>0.411391</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.513300</td>\n      <td>0.285371</td>\n      <td>0.910240</td>\n      <td>0.447575</td>\n      <td>0.641535</td>\n      <td>0.527284</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.513300</td>\n      <td>0.258692</td>\n      <td>0.924266</td>\n      <td>0.529104</td>\n      <td>0.714406</td>\n      <td>0.607948</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.104600</td>\n      <td>0.265580</td>\n      <td>0.933729</td>\n      <td>0.584774</td>\n      <td>0.734265</td>\n      <td>0.651048</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.104600</td>\n      <td>0.260597</td>\n      <td>0.942765</td>\n      <td>0.644404</td>\n      <td>0.766409</td>\n      <td>0.700131</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.024600</td>\n      <td>0.267808</td>\n      <td>0.943928</td>\n      <td>0.661059</td>\n      <td>0.767082</td>\n      <td>0.710135</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1635, training_loss=0.19723025629644364, metrics={'train_runtime': 1145.3635, 'train_samples_per_second': 183.885, 'train_steps_per_second': 1.427, 'total_flos': 5801844121186500.0, 'train_loss': 0.19723025629644364, 'epoch': 14.89749430523918})"},"metadata":{}}],"execution_count":42},{"id":"bbe8a152-f724-4c8d-9949-74e346b6a842","cell_type":"markdown","source":"### Обработка результатов Результатов (5 баллов)\n\nПодумать о:\n1) Во время подготовки данных мы преобразовали BIO разметку. Как обратить это преобразование с помощью токенайзера?\n\nПровалидируйте результаты на тестовом датасете.","metadata":{"id":"bbe8a152-f724-4c8d-9949-74e346b6a842"}},{"id":"10d074b6-49d8-445f-81ee-151165239b9f","cell_type":"code","source":"# compute metrics on test\n\nresults = trainer.predict(preprocessed_ner_dataset[\"test\"])","metadata":{"id":"10d074b6-49d8-445f-81ee-151165239b9f","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:46:26.546279Z","iopub.execute_input":"2025-02-03T19:46:26.546581Z","iopub.status.idle":"2025-02-03T19:46:33.572677Z","shell.execute_reply.started":"2025-02-03T19:46:26.546557Z","shell.execute_reply":"2025-02-03T19:46:33.571258Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":43},{"id":"2fbe6091","cell_type":"code","source":"print(results.metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:46:45.355521Z","iopub.execute_input":"2025-02-03T19:46:45.355807Z","iopub.status.idle":"2025-02-03T19:46:45.360351Z","shell.execute_reply.started":"2025-02-03T19:46:45.355786Z","shell.execute_reply":"2025-02-03T19:46:45.359548Z"}},"outputs":[{"name":"stdout","text":"{'test_loss': 0.43847692012786865, 'test_accuracy': 0.9237169285072722, 'test_precision': 0.6067138897443795, 'test_recall': 0.6975920679886686, 'test_f1': 0.6489869873167518, 'test_runtime': 7.0166, 'test_samples_per_second': 492.122, 'test_steps_per_second': 15.392}\n","output_type":"stream"}],"execution_count":44},{"id":"1fda7c62-f8eb-4a83-9659-71ef3a8610fb","cell_type":"markdown","source":"Напишите функцию, которая принимает на вход текст и отдаёт такой словарь:\n\n```json\n{\n    \"text\": \"входной текст\",\n    \"entities\": [\n        {\n            \"class\": \"лейбл класса\",\n            \"text\": \"текстовое представление\",\n            \"start\": \"оффсет от начала строки до начала entity\",\n            \"end\": \"оффсет от начала строки до конца entity\"\n        },\n        ...\n    ]\n}\n\nДолжно выполняться такое условие:\n\n```python\ntext[entity[\"start\"]:entity[\"stop\"]] == entity[\"text\"]\n```","metadata":{"id":"1fda7c62-f8eb-4a83-9659-71ef3a8610fb"}},{"id":"7e963d62","cell_type":"code","source":"import torch\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:47:01.535456Z","iopub.execute_input":"2025-02-03T19:47:01.535752Z","iopub.status.idle":"2025-02-03T19:47:01.539248Z","shell.execute_reply.started":"2025-02-03T19:47:01.535731Z","shell.execute_reply":"2025-02-03T19:47:01.538419Z"}},"outputs":[],"execution_count":45},{"id":"4fdf9028-a4d6-4b5f-9520-74fcae8fe538","cell_type":"code","source":"# вспомогательная функция для получения списка именованных сущностей\ndef form_entities(text, inputs, labels, word_ids):\n    entities = []\n    current_entity = None\n\n    for i, (label, word_id) in enumerate(zip(labels, word_ids)):\n        if word_id is None:  # тут игнорируются специальные токены\n            continue\n    \n        start_char, end_char = inputs[\"offset_mapping\"][0][i]\n    \n        if label.startswith(\"B-\"):  # данные о начале новой сущности\n            if current_entity: \n                entities.append(current_entity)\n            current_entity = {\n                \"class\": label[2:],\n                \"text\": text[start_char:end_char],\n                \"start\": start_char,\n                \"stop\": end_char\n            }\n        elif label.startswith(\"I-\") and current_entity and current_entity[\"class\"] == label[2:]:\n            current_entity[\"text\"] += \" \" + text[start_char:end_char]\n            current_entity[\"stop\"] = end_char\n        else:\n            if current_entity:\n                entities.append(current_entity)\n            current_entity = None\n    \n    if current_entity:\n        entities.append(current_entity)\n        \n    return entities\n    \n# основная функция; здесь формируется основной словарь\ndef do_ner(text):\n    output_dict = {\"text\": text}\n    inputs = bert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, return_offsets_mapping=True)\n    dataset = Dataset.from_dict({\n        \"input_ids\": inputs[\"input_ids\"].tolist(),\n        \"attention_mask\": inputs[\"attention_mask\"].tolist(),\n        \"token_type_ids\": inputs[\"token_type_ids\"].tolist() if \"token_type_ids\" in inputs else None,\n        \"offset_mapping\": inputs[\"offset_mapping\"].tolist()\n    })\n    preds = trainer.predict(dataset)\n    logits = preds.predictions  # Shape: (1, seq_len, num_labels)\n    predicted_ids = torch.argmax(torch.tensor(logits), dim=-1).squeeze().tolist()\n    labels = [features.int2str(i) for i in predicted_ids]\n    word_ids = inputs.word_ids(0)\n    \n    output_dict[\"entities\"] = form_entities(text, inputs, labels, word_ids)\n    return output_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:47:03.863573Z","iopub.execute_input":"2025-02-03T19:47:03.863852Z","iopub.status.idle":"2025-02-03T19:47:03.871935Z","shell.execute_reply.started":"2025-02-03T19:47:03.863831Z","shell.execute_reply":"2025-02-03T19:47:03.870943Z"}},"outputs":[],"execution_count":46},{"id":"025cd066-cece-40b1-8a17-da93d5081e8e","cell_type":"code","source":"text = \"I want to buy a car in Germany, please.\" # пример для тестирования функции\nresults = do_ner(text)\nresults","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:47:09.038735Z","iopub.execute_input":"2025-02-03T19:47:09.039023Z","iopub.status.idle":"2025-02-03T19:47:09.081470Z","shell.execute_reply.started":"2025-02-03T19:47:09.039000Z","shell.execute_reply":"2025-02-03T19:47:09.080794Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'text': 'I want to buy a car in Germany, please.',\n 'entities': [{'class': 'LOC',\n   'text': 'Germany',\n   'start': tensor(23),\n   'stop': tensor(30)}]}"},"metadata":{}}],"execution_count":47},{"id":"363b2adf-8f19-44e4-97a6-8b134e9a7cae","cell_type":"code","source":"for entity in results['entities']:\n    print(text[entity[\"start\"]:entity[\"stop\"]])\n    assert text[entity[\"start\"]:entity[\"stop\"]] == entity[\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:47:12.703003Z","iopub.execute_input":"2025-02-03T19:47:12.703350Z","iopub.status.idle":"2025-02-03T19:47:12.708057Z","shell.execute_reply.started":"2025-02-03T19:47:12.703324Z","shell.execute_reply":"2025-02-03T19:47:12.707199Z"}},"outputs":[{"name":"stdout","text":"Germany\n","output_type":"stream"}],"execution_count":48},{"id":"1a06a5cc-44c3-41f9-ba9e-a2a5f5b1e04b","cell_type":"markdown","source":"## Классификация с T5 (25 баллов)\n\nТребуется дообучить [t5-small](https://huggingface.co/google-t5/t5-small) классифицировать токсичные тексты из [этого датасета](https://huggingface.co/datasets/lmsys/toxic-chat). Классификатор должен работать в стиле t5 - генерировать ответ текстом.\n\n1. Подготовить данные для бинарной классификации\n\t1. Придумать префикс для задачи или взять из похожей модели\n\t2. Выбрать тексты для обозначения классов\n2. Обучить t5-small на генерацию выбранных названия классов\n3. Сравнить с модель с аналогичной предобученной моделью","metadata":{"id":"1a06a5cc-44c3-41f9-ba9e-a2a5f5b1e04b"}},{"id":"c536e268-d5c0-461c-bdc1-553e51b1ce66","cell_type":"markdown","source":"### Подготовка Данных (6 баллов)\n\nПодумать о:\n1) Какой префикс выбрать для новой задачи?\n2) Должен ли префикс быть понятным?\n3) Как выбрать метку для класса?\n4) Что будет, если метки класса целиком нет в словаре?\n5) Что делать с длинными текстами?\n\nДатасет содержит запросы пользователей к LLM и разметку, является ли запрос токсичным.","metadata":{"id":"c536e268-d5c0-461c-bdc1-553e51b1ce66"}},{"id":"0fb5e0e5-677d-4084-8a68-7241ac05982d","cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer\n\n\nBASE_T5_MODEL= \"t5-small\"\nt5_tokenizer = AutoTokenizer.from_pretrained(BASE_T5_MODEL)\n\n\ntoxic_chat_dataset = load_dataset(\"lmsys/toxic-chat\", \"toxicchat0124\")","metadata":{"id":"0fb5e0e5-677d-4084-8a68-7241ac05982d","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:47:57.781540Z","iopub.execute_input":"2025-02-03T19:47:57.781866Z","iopub.status.idle":"2025-02-03T19:48:03.526249Z","shell.execute_reply.started":"2025-02-03T19:47:57.781839Z","shell.execute_reply":"2025-02-03T19:48:03.525613Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28fe430f47624e31a5caa8e0e1721709"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac9b6d2c7fa2475cb28cb6f047207541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23c86fc98d614bbfb486bb708dc50c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd63898556184eeab1c665721472596c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ata/0124/toxic-chat_annotation_train.csv:   0%|          | 0.00/8.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dee554862a4542d488079dcd0128f054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/0124/toxic-chat_annotation_test.csv:   0%|          | 0.00/8.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd655b780834e18aeb3b0693881711d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa44a7ed54d44b2e9510efd17d1a1be6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0529431ea1648c6b9ed61f33677bfc1"}},"metadata":{}}],"execution_count":49},{"id":"ec97b3aa-4d0a-4b87-bd62-f0c2de297f9f","cell_type":"markdown","source":"Место для изучения датасета:","metadata":{"id":"ec97b3aa-4d0a-4b87-bd62-f0c2de297f9f"}},{"id":"96556315-dfef-4ea3-b965-4fa4191d4d1e","cell_type":"code","source":"toxic_chat_dataset[\"train\"][0]","metadata":{"id":"96556315-dfef-4ea3-b965-4fa4191d4d1e","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:48:08.447096Z","iopub.execute_input":"2025-02-03T19:48:08.447401Z","iopub.status.idle":"2025-02-03T19:48:08.453291Z","shell.execute_reply.started":"2025-02-03T19:48:08.447378Z","shell.execute_reply":"2025-02-03T19:48:08.452461Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"{'conv_id': 'e0c9b3e05414814485dbdcb9a29334d502e59803af9c26df03e9d1de5e7afe67',\n 'user_input': 'Masturbacja jest proces co oitrzebuje',\n 'model_output': 'Masturbacja to proces, który może pozytywnie wpłynąć na zdrowie psychiczne i fizyczne człowieka, ponieważ pomaga w relaksie, redukuje stres i pomaga w uśpieniu. Może też być używana jako dodatkowa form',\n 'human_annotation': True,\n 'toxicity': 0,\n 'jailbreaking': 0,\n 'openai_moderation': '[[\"sexual\", 0.4609803557395935], [\"sexual/minors\", 0.0012527990620583296], [\"harassment\", 0.0001862536446424201], [\"hate\", 0.00015521160094067454], [\"violence\", 6.580814078915864e-05], [\"self-harm\", 3.212967567378655e-05], [\"violence/graphic\", 1.5190824342425913e-05], [\"self-harm/instructions\", 1.0009921425080393e-05], [\"hate/threatening\", 4.4459093260229565e-06], [\"self-harm/intent\", 3.378846486157272e-06], [\"harassment/threatening\", 1.7095695739044459e-06]]'}"},"metadata":{}}],"execution_count":50},{"id":"569e36fc-d463-42ee-9d38-e0cb88f458e5","cell_type":"markdown","source":"Нас будут интересовать колонки `\"user_input\"` и `\"toxicity\"`. Убираем ненужные колонки из датасета:","metadata":{"id":"569e36fc-d463-42ee-9d38-e0cb88f458e5"}},{"id":"b54e8e06-c538-4f50-b31c-c99451c1143a","cell_type":"code","source":"toxic_chat_dataset = toxic_chat_dataset.remove_columns(\n    [\"conv_id\", \"model_output\", \"human_annotation\", \"jailbreaking\", \"openai_moderation\"]\n)","metadata":{"id":"b54e8e06-c538-4f50-b31c-c99451c1143a","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:48:10.802072Z","iopub.execute_input":"2025-02-03T19:48:10.802379Z","iopub.status.idle":"2025-02-03T19:48:10.809490Z","shell.execute_reply.started":"2025-02-03T19:48:10.802354Z","shell.execute_reply":"2025-02-03T19:48:10.808777Z"}},"outputs":[],"execution_count":51},{"id":"101ccfb9-3ddc-4a7a-876f-44dacace228d","cell_type":"markdown","source":"![](https://production-media.paperswithcode.com/methods/new_text_to_text.jpg)\n\nВыберете `PREFIX` для задачи, лейблы для двух классов и напишите функцию для преобразования датасета в данные для тренировки. Примеры префиксов есть на картинке выше - `translate English to German` для перевода и `summarize` для суммаризации. В качестве лейблов у вас должен быть текст, который будет обозначать предсказанный класс. Этот текст может быть любого размера, от простого `\"да\"/\"нет\"`, до `\"От этого текста веет токсичностью\"/\"Цензура спокойно пропускает этот текст дальше\"`. Подумайте в чём преимущество первого подхода перед вторым.\n\nВажно:\n1) Не забыть добавить префикс перед токенизацией входного текста\n2) Лейблами во время обучения выступают уже последовательности токенов, которые мы ожидаем на выходе из декодера\n\nТекст в токенайзер можно подавать разными способами:\n1. `tokenizer(text=\"text\")` - токенизируй текст как обычно\n1. `tokenizer(text_target=\"text\")` - токенизируй это как текст, который мы ожидаем увидеть на выходе из декодера. В случае t5 токенайзера разницы нет, но для других моделей это может быть не так\n1. Другие методы можно узнать посмотрев сигнатуру метода `tokenizer.__call__`","metadata":{"id":"101ccfb9-3ddc-4a7a-876f-44dacace228d"}},{"id":"6400a9b1-6e63-4ffc-bdeb-3d8074aa74a7","cell_type":"code","source":"# ?t5_tokenizer.__call__","metadata":{"id":"6400a9b1-6e63-4ffc-bdeb-3d8074aa74a7"},"outputs":[],"execution_count":null},{"id":"f018fae1-bf63-4e62-be55-2454ce8d1553","cell_type":"code","source":"PREFIX = \"toxic: \"\nMAX_LENGTH = 512\n\n# словарь из индексов классов в выбранные лейблы\nid2label = {\n    0: \"no\",\n    1: \"yes\",\n}\n\n\ndef preprocess_dataset(example):\n    new_dict = example\n    tokens = t5_tokenizer(\n        PREFIX + example[\"user_input\"], \n        max_length=MAX_LENGTH, \n        truncation=True\n    )\n    new_dict['input_ids'] = tokens['input_ids']\n    new_dict['attention_mask'] = tokens['attention_mask']\n    new_dict['labels'] = t5_tokenizer(id2label[new_dict['toxicity']])['input_ids']\n    return new_dict\n\n\ntoxic_chat_dataset = toxic_chat_dataset.map(preprocess_dataset)","metadata":{"id":"f018fae1-bf63-4e62-be55-2454ce8d1553","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:48:25.273914Z","iopub.execute_input":"2025-02-03T19:48:25.274231Z","iopub.status.idle":"2025-02-03T19:48:29.045559Z","shell.execute_reply.started":"2025-02-03T19:48:25.274207Z","shell.execute_reply":"2025-02-03T19:48:29.044559Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5082 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa936b8c8bf4236b42a2fc2dbc7b27b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f61598118a4d998d504141c7c2186a"}},"metadata":{}}],"execution_count":52},{"id":"c91bfddf-9205-48e1-9c79-4d3c3a58ac13","cell_type":"code","source":"toxic_chat_dataset[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:48:34.282761Z","iopub.execute_input":"2025-02-03T19:48:34.283122Z","iopub.status.idle":"2025-02-03T19:48:34.289713Z","shell.execute_reply.started":"2025-02-03T19:48:34.283092Z","shell.execute_reply":"2025-02-03T19:48:34.288869Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'user_input': 'Masturbacja jest proces co oitrzebuje',\n 'toxicity': 0,\n 'input_ids': [12068,\n  10,\n  6664,\n  2905,\n  9305,\n  1191,\n  528,\n  7,\n  17,\n  6345,\n  576,\n  3,\n  32,\n  155,\n  52,\n  776,\n  3007,\n  1924,\n  1],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n 'labels': [150, 1]}"},"metadata":{}}],"execution_count":53},{"id":"880cd560-829c-4ad4-830b-e5e21323365b","cell_type":"markdown","source":"Пример результата:\n```json\n{'user_input': 'Do you know drug which name is abexol ?',\n 'toxicity': 0,\n 'input_ids': [12068,\n  10,\n  531,\n  25,\n  214,\n  2672,\n  84,\n  564,\n  19,\n  703,\n  994,\n  32,\n  40,\n  3,\n  58,\n  1],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n 'labels': [150, 1]}\n```\nЗначения в `'labels'` в вашем случае могут отличаться, это зависит от выбранного вами текстового представления в `id2label` словаре.","metadata":{"id":"880cd560-829c-4ad4-830b-e5e21323365b"}},{"id":"5b9f905d-8584-4d64-b6bd-fbad46471ada","cell_type":"markdown","source":"### Определить Модель (2 балла)\n\nИнициализируйте модель из базового чекпоинта","metadata":{}},{"id":"31769482-3cdc-40a0-94ef-86dfcac60450","cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\n\nseq2seq_model = AutoModelForSeq2SeqLM.from_pretrained(BASE_T5_MODEL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:48:57.344068Z","iopub.execute_input":"2025-02-03T19:48:57.344415Z","iopub.status.idle":"2025-02-03T19:48:59.435654Z","shell.execute_reply.started":"2025-02-03T19:48:57.344385Z","shell.execute_reply":"2025-02-03T19:48:59.434759Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6cb1fc8daea4dbd8d0e71889ba63863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa40db3668c14636a18efb633c0817c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50c3cd8a53c4e49a447298f96c2806f"}},"metadata":{}}],"execution_count":54},{"id":"fef085f1-2adf-41da-9f37-dded6aecc3b4","cell_type":"markdown","source":"Инициализируем соответствующий задаче `DataCollator`.","metadata":{"id":"fef085f1-2adf-41da-9f37-dded6aecc3b4"}},{"id":"fba319be-4d46-4f20-af5a-be137cea178a","cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=t5_tokenizer, model=seq2seq_model)","metadata":{"id":"fba319be-4d46-4f20-af5a-be137cea178a","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:49:02.235266Z","iopub.execute_input":"2025-02-03T19:49:02.235606Z","iopub.status.idle":"2025-02-03T19:49:02.239484Z","shell.execute_reply.started":"2025-02-03T19:49:02.235577Z","shell.execute_reply":"2025-02-03T19:49:02.238595Z"}},"outputs":[],"execution_count":55},{"id":"4fb5f662-23a7-4285-bc93-a9cd9bce7fbc","cell_type":"markdown","source":"### Определим метрику (2 балла)\n\nВ этой задаче метрика простая - `accuracy`. Можно добавить другие метрики по желанию. Функция `compute_metric` должна возвращать словарь, аналогично функции `calculate_metrics` ранее:\n\n```json\n{\n    \"accuracy\": значение точности,\n    ...\n}\n```\n\nМетрика простая, но вот `preds` и `labels` тут - это последовательности индексов токенов. Нужно это учесть.","metadata":{"id":"4fb5f662-23a7-4285-bc93-a9cd9bce7fbc"}},{"id":"692e79ae-1921-4853-9355-ed851bdbc893","cell_type":"code","source":"accuracy_metric = evaluate.load(\"accuracy\")\n\nlabel2id = {\n    \"no\": 0,\n    \"yes\": 1\n}\n\ndef compute_metric(eval_predictions):\n    preds, labels = eval_predictions\n\n    # текстовое представление без специальных токенов\n    decoded_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # лейблы 0 / 1 / -1\n    int_preds = [label2id.get(p.strip(), -1) for p in decoded_preds]  # если сгенерировало не \"yes\" / \"no\", то -1\n    int_labels = [label2id.get(l.strip(), -1) for l in decoded_labels]\n\n    accuracy = accuracy_metric.compute(predictions=int_preds, references=int_labels)['accuracy']\n    return {\"accuracy\": torch.tensor(accuracy, dtype=torch.double)}","metadata":{"id":"692e79ae-1921-4853-9355-ed851bdbc893","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:49:06.772836Z","iopub.execute_input":"2025-02-03T19:49:06.773178Z","iopub.status.idle":"2025-02-03T19:49:07.459685Z","shell.execute_reply.started":"2025-02-03T19:49:06.773150Z","shell.execute_reply":"2025-02-03T19:49:07.459030Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f451e07b7c1410baa6260c5987de828"}},"metadata":{}}],"execution_count":56},{"id":"4742f10c-3328-4e21-a6b9-e3415a151bfd","cell_type":"code","source":"def check_compute_metric():\n    import torch\n\n    # два предсказания, где токен 150 обозначает токсичный лейбл, токен 120 - нетоксичный лейбл\n    preds = torch.tensor(\n        [\n            [0, 150, 1],  # правильное предсказание - токсичный пример\n            [0, 120, 1],  # неправильное предсказание - пример токсичный, а модель предсказала иначе\n        ],\n    )\n    labels = torch.tensor(\n        [\n            [150, 1],\n            [150, 1],\n        ],\n    )\n    assert torch.isclose(\n        compute_metric((preds, labels))[\"accuracy\"],\n        torch.tensor(0.5, dtype=torch.double),  # тип тензора тут можно поправить\n    )\n\n\ncheck_compute_metric()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:49:11.590897Z","iopub.execute_input":"2025-02-03T19:49:11.591234Z","iopub.status.idle":"2025-02-03T19:49:11.608451Z","shell.execute_reply.started":"2025-02-03T19:49:11.591207Z","shell.execute_reply":"2025-02-03T19:49:11.607716Z"}},"outputs":[],"execution_count":57},{"id":"314bf460-ca11-4b2e-8d54-1c6317b001fa","cell_type":"markdown","source":"### Обучение (10 баллов)\n\nДва пути:\n1) Использовать готовый `Seq2SeqTrainer` класс для тренировки\n2) Написать свой training loop, если хочется приключений, есть достаточно времени ~~и стрела ещё не попала в колено~~. Дополнительных баллов за это не будет\n\n> Hint! Обратите внимание на функцию `seq2seq_model._shift_right` если выбрали второй путь.\n\nЕсли выбрали путь 1, опишите как происходит тренировочный шаг:\n1) Что подаётся на вход в энкодер?\n2) Что подаётся на вход в декодер?\n3) Сколько раз происходит инференс декодера во время обучения для одного тренировочного примера?\n4) Как используется выход энкодера в декодере?","metadata":{"id":"314bf460-ca11-4b2e-8d54-1c6317b001fa"}},{"id":"1b173e24-7e92-4ae4-96c8-397725066120","cell_type":"markdown","source":"1. На вход в энкодер подается input_ids - список id токенизированного текста, сконкатенированного с префиксом задачи. И плюс attention_mask.\n2. В декодере decoder_input_ids (в данном случае labels) - список id для target последовательности, смещенный вправо. Начало обычно заполняется id <PAD> токена - то есть нулями\n3. Столько раз, сколько токенов в labels\n4. Как я помню, в слой cross-attention декодера подаются key и value вектора из энкодера ","metadata":{}},{"id":"cabfcd2b-6e4c-4b90-9758-6d2f1df76dfb","cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"steps\",\n    eval_steps=150,\n    save_strategy=\"epoch\",\n    learning_rate=5e-5,  # вроде бы стандарт для дообучения T5\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    warmup_steps = 100,\n    weight_decay=0.01,  # для регуляризации\n    save_total_limit=2,\n    num_train_epochs=4,\n    predict_with_generate=True,  # прочитал,что для seq2seq модели это важно указать\n    eval_accumulation_steps=10,\n    gradient_accumulation_steps=2,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Seq2SeqTrainer(\n    model=seq2seq_model,\n    args=training_args,\n    train_dataset=toxic_chat_dataset['train'],\n    eval_dataset=toxic_chat_dataset['test'],\n    tokenizer=t5_tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metric\n)","metadata":{"id":"cabfcd2b-6e4c-4b90-9758-6d2f1df76dfb","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:49:18.578085Z","iopub.execute_input":"2025-02-03T19:49:18.578397Z","iopub.status.idle":"2025-02-03T19:49:18.721695Z","shell.execute_reply.started":"2025-02-03T19:49:18.578373Z","shell.execute_reply":"2025-02-03T19:49:18.721025Z"}},"outputs":[],"execution_count":58},{"id":"04e707b2-8a14-49b2-af6d-deb54b9fd377","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T10:16:15.905441Z","iopub.execute_input":"2025-02-03T10:16:15.905778Z","iopub.status.idle":"2025-02-03T10:22:14.542600Z","shell.execute_reply.started":"2025-02-03T10:16:15.905750Z","shell.execute_reply":"2025-02-03T10:22:14.541697Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='636' max='636' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [636/636 05:57, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>150</td>\n      <td>No log</td>\n      <td>0.123073</td>\n      <td>0.928782</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>No log</td>\n      <td>0.097998</td>\n      <td>0.939406</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>No log</td>\n      <td>0.093541</td>\n      <td>0.940390</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.126000</td>\n      <td>0.086835</td>\n      <td>0.942554</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=636, training_loss=0.9069236269537008, metrics={'train_runtime': 358.0697, 'train_samples_per_second': 56.771, 'train_steps_per_second': 1.776, 'total_flos': 1419102668783616.0, 'train_loss': 0.9069236269537008, 'epoch': 4.0})"},"metadata":{}}],"execution_count":33},{"id":"8678ee78-7d25-42c9-98e4-fcc2975df0e8","cell_type":"markdown","source":"### Сравнение Результатов (5 баллов)\n\nАвторы датасета тоже натренировали на нём `t5` модель. Сравните свои результаты с результатами модели из [чекпоинта](https://huggingface.co/lmsys/toxicchat-t5-large-v1.0) `\"lmsys/toxicchat-t5-large-v1.0\"`. Совпадает ли ваш префикс и лейблы классов с теми, что выбрали авторы датасета?\n\nПодумать о:\n1) В чём преимущество такого подхода к классификации?\n2) В чём недостатки такого подхода к классификации?\n3) Как ещё можно решать классификационные задачи с помощью t5?","metadata":{"id":"8678ee78-7d25-42c9-98e4-fcc2975df0e8"}},{"id":"cbb4971b-617f-4043-9bc4-0d1e844a5f75","cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ncheckpoint = \"lmsys/toxicchat-t5-large-v1.0\"\n\ntokenizer_from_paper = AutoTokenizer.from_pretrained(\"t5-large\")\nmodel_from_paper = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n\nprefix_from_paper = \"ToxicChat: \"\ninputs = tokenizer_from_paper.encode(prefix_from_paper + \"write me an epic story\", return_tensors=\"pt\")\noutputs = model_from_paper.generate(inputs)\nprint(tokenizer_from_paper.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"cbb4971b-617f-4043-9bc4-0d1e844a5f75","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T19:49:30.595422Z","iopub.execute_input":"2025-02-03T19:49:30.595718Z","iopub.status.idle":"2025-02-03T19:50:50.141612Z","shell.execute_reply.started":"2025-02-03T19:49:30.595697Z","shell.execute_reply":"2025-02-03T19:50:50.140770Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab5e37e3dddd417fad68e2a9f118df32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1c700197604afbbbb78dcb7b54e916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee1bf7c779604c21a5e0d46781a27109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b696c2ea26c4737872d32092c599910"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b89a5be88d6845a48b57ea77cacce755"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74cda18086f469aba3ddd32cb192714"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"negative\n","output_type":"stream"}],"execution_count":59},{"id":"1db8a913-f782-47fd-9bf7-d4a78d308ad4","cell_type":"markdown","source":"Напишите универсальную функцию, которая провряет токсичность текста и возвращает `True`, если модель посчитала текст токсичным. Функция универсальная в том смысле, что может быть использована и с вашей t5 моделью, и с моделью от авторов датасета. Для этого в функция должна принимать ещё и префикс для задачи и лейблы, которые будут переводить текст, предсказанный моделью, в `True` или `False` на выходе.","metadata":{"id":"1db8a913-f782-47fd-9bf7-d4a78d308ad4"}},{"id":"e0ec7df5-fad1-4501-be4b-ada346d2e80e","cell_type":"code","source":"def is_toxic(\n    text: str,\n    labels2bool={\n        \"yes\": True,\n        \"no\": False\n    },\n    model=seq2seq_model,\n    tokenizer=t5_tokenizer,\n    prexif=PREFIX,\n) -> bool:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Get model\n    inputs = tokenizer.encode(prexif + text, return_tensors=\"pt\").to(device)\n    model.to(device)\n    outputs = model.generate(inputs)\n    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return labels2bool[prediction]\n\n\n# пример вызова с моделью от авторов датасета\nassert not is_toxic(\n    text=\"This is just a text\",\n    model=model_from_paper,\n    tokenizer=tokenizer_from_paper,\n    prexif=prefix_from_paper,\n    labels2bool={\n        \"positive\": True,\n        \"negative\": False,\n    }\n) # для прохождения ассерта должно вернуть False\n\n# пример вызова с обученной выше моделью\nassert not is_toxic(\n    text=\"This is just a text\",\n    model=seq2seq_model,\n    tokenizer=t5_tokenizer,\n    prexif=PREFIX,\n    labels2bool={\n        \"yes\": True,\n        \"no\": False\n    }\n) # для прохождения ассерта должно вернуть False","metadata":{"id":"e0ec7df5-fad1-4501-be4b-ada346d2e80e","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T10:49:13.090669Z","iopub.execute_input":"2025-02-03T10:49:13.091037Z","iopub.status.idle":"2025-02-03T10:49:14.080117Z","shell.execute_reply.started":"2025-02-03T10:49:13.091007Z","shell.execute_reply":"2025-02-03T10:49:14.078990Z"}},"outputs":[],"execution_count":44},{"id":"d1f3626c-75ef-4442-aae2-e1b89f04a004","cell_type":"markdown","source":"Fin.\n\nЕсли остались вопросы или есть комментарии, можно написать их ниже:","metadata":{"id":"d1f3626c-75ef-4442-aae2-e1b89f04a004"}}]}