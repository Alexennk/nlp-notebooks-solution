{"cells":[{"cell_type":"markdown","metadata":{"id":"HTRKQXmpWPaB"},"source":["# Домашнее задание: Промптинг на Python\n","\n","## Введение\n","В данном задании мы будем работать с API онлайн моделей через together.ai. Эти модели предоставляют $5 кредита при регистрации, что позволит вам провести необходимые эксперименты. Вначале мы познакомимся с API на практике, а затем выполним три основных задания.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"6KuK9qByWh9v"},"source":["## Задача 1: Знакомство с API together.ai (5 баллов)\n","1. Зарегистрируйтесь на платформе [together.ai](https://together.ai/) и получите API ключ.\n","2. Используйте приведенный ниже код для вызова модели Llama через together.ai:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbp5wzghWqLQ"},"outputs":[],"source":["import requests\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7JJFWgwWN2O"},"outputs":[],"source":["# Вставьте свой API ключ\n","API_KEY = \"Ваш ключ из https://api.together.ai/\"\n","# Не забудьте удалить ключ перед сдачей задания\n","\n","# Параметры модели\n","url = \"https://api.together.ai/v1/completions\"\n","data = {\n","    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n","    \"prompt\": \"Translate the following English text to French: 'Hello, how are you?'\",\n","    \"max_tokens\": 50\n","}\n","headers = {\n","    \"Authorization\": f\"Bearer {API_KEY}\",\n","    \"Content-Type\": \"application/json\"\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","if response.status_code == 200:\n","    print(\"Response:\", response.json()[\"choices\"][0][\"text\"])\n","else:\n","    print(\"Error:\", response.status_code, response.text)"]},{"cell_type":"markdown","metadata":{"id":"tPpeWK10CXAM"},"source":["Выше описан пример запроса в completion формате, то есть подается поле `prompt`, которое напрямую подается в модель. Как мы помним, у Llama 3.x моделей есть свой формат входных данных, так что лучше подавать его. Отформатируем наш запрос."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2_TqmR8CXAN"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct\")\n","prompt = tokenizer.apply_chat_template(\n","    [{\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"}],\n","    add_generation_prompt=True,\n","    tokenize=False\n",")\n","print(prompt)"]},{"cell_type":"markdown","metadata":{"id":"HYrAvTe2CXAN"},"source":["И пошлем его в API:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"in4jqiGMCXAN"},"outputs":[],"source":["data = {\n","    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n","    \"prompt\": prompt,\n","    \"max_tokens\": 50\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","if response.status_code == 200:\n","    print(\"Response:\", response.json()[\"choices\"][0][\"text\"])\n","else:\n","    print(\"Error:\", response.status_code, response.text)"]},{"cell_type":"markdown","metadata":{"id":"McclIGFFCXAN"},"source":["Это еще не все! Чтобы не заниматься форматированием на стороне клиента, почти все провайдеры поддерживают работу с сообщениями и ролями и берут работу по форматированию на себя. Для этого вместо поля prompt нужно послать поле messages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCOPpHxVCXAO"},"outputs":[],"source":["data = {\n","    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n","    \"messages\": [{\"role\": \"user\", \"content\": \"Translate the following English text to French: 'Hello, how are you?'\"}],\n","    \"max_tokens\": 50\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","if response.status_code == 200:\n","    print(\"Response:\", response.json()[\"choices\"][0][\"text\"])\n","else:\n","    print(\"Error:\", response.status_code, response.text)"]},{"cell_type":"markdown","metadata":{"id":"q7JJqb1MWsMt"},"source":["3. Модифицируйте запрос, чтобы:\n","   - Решить простую математическую задачу (например, сложение чисел).\n","   - Сгенерировать текст на тему \"Как искусственный интеллект меняет мир\".\n"]},{"cell_type":"markdown","metadata":{"id":"gwOAcwsNWupO"},"source":["## Задача 2: Решение математических задач через Chain of Thought (10 баллов)\n","\n","Используя подход Chain of Thought (CoT), решите 10 математических задач и измерьте accuracy модели.\n"]},{"cell_type":"markdown","metadata":{"id":"gEZbxEB6W0wi"},"source":["1. Создайте функцию, которая формирует запросы для модели с использованием CoT:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nm4wy0WzWyIo"},"outputs":[],"source":["def solve_math_cot(prompt: str) -> str:\n","    cot_prompt = f\"Давайте подумаем шаг за шагом, чтобы решить эту задачу: {prompt}\"\n","    # Подставьте сюда вызов API\n","    return response_text"]},{"cell_type":"markdown","metadata":{"id":"hvnb50YvXK1q"},"source":["2. Подготовьте 5 задач (например, из школьной программы) и выполните их решение через модель."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_f0BQ05W7KR"},"outputs":[],"source":["# Пример запроса для задачи умножения\n","example_prompt = \"Чему равно 23 умножить на 47?\"\n","cot_prompt = f\"Давайте подумаем шаг за шагом, чтобы решить эту задачу: {example_prompt}\"\n","\n","data = {\n","    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n","    \"prompt\": cot_prompt,\n","    \"max_tokens\": 100\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","if response.status_code == 200:\n","    print(\"Ответ:\", json.loads(response.text)[\"choices\"][0][\"text\"].strip())\n","else:\n","    print(\"Ошибка:\", response.status_code, response.text)\n"]},{"cell_type":"markdown","metadata":{"id":"yXzxK5eSXqlq"},"source":["3. Подсчитайте количество правильно решённых задач (accuracy)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhXt5PDuXvXz"},"outputs":[],"source":["My_accuracy ="]},{"cell_type":"markdown","metadata":{"id":"3y5u-7XJX0Q4"},"source":["## Задача 3: Классификация IMDB через few-shot и zero-shot (10 баллов)\n","\n","Проведите классификацию отзывов IMDB на позитивные и негативные с использованием few-shot и zero-shot подходов.\n"]},{"cell_type":"markdown","metadata":{"id":"0DJp3h-jX4Pj"},"source":["1. Выберите 5 примеров для few-shot обучения (например, 2 позитивных и 3 негативных отзыва).\n","2. Реализуйте запросы к модели в режиме zero-shot и few-shot:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ry9ro4p1XtKx"},"outputs":[],"source":["def classify_review(prompt: str, examples: List[str] = None) -> str:\n","    few_shot_prompt = \"\"\"\n","    {examples}\n","    Теперь классифицируйте отзыв: {prompt}\n","    \"\"\" if examples else f\"Классифицируйте следующий отзыв: {prompt}\"\n","    # Подставьте сюда вызов API\n","    return response_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvHCuAZoYAU-"},"outputs":[],"source":["# Пример zero-shot классификации\n","review_prompt = \"Этот фильм был потрясающим! Сюжет увлекательный, а актеры великолепны.\"\n","zero_shot_prompt = f\"Классифицируйте следующий отзыв как позитивный или негативный: {review_prompt}\"\n","\n","data = {\n","    \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n","    \"prompt\": zero_shot_prompt,\n","    \"max_tokens\": 50\n","}\n","\n","response = requests.post(url, headers=headers, json=data)\n","if response.status_code == 200:\n","    print(\"Классификация:\", json.loads(response.text)[\"choices\"][0][\"text\"].strip())\n","else:\n","    print(\"Ошибка:\", response.status_code, response.text)\n"]},{"cell_type":"markdown","metadata":{"id":"nj-IHKMjYODp"},"source":["3. Сравните результаты, объяснив различия между zero-shot и few-shot подходами."]},{"cell_type":"markdown","metadata":{"id":"feZB1KQiYQpa"},"source":["## Задача 4: Self-reflection и качество ответов модели (10 баллов)\n","\n","Проверьте, как self-reflection влияет на качество ответов модели.\n"]},{"cell_type":"markdown","metadata":{"id":"rDn-C1PwYTXQ"},"source":["1. Реализуйте функцию self-reflection, которая анализирует ответ модели и предлагает улучшения:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7C1Lu59BYOzN"},"outputs":[],"source":["def self_reflection(prompt: str) -> str:\n","    reflection_prompt = f\"Проанализируйте ответ и предложите улучшения: {prompt}\"\n","    # Подставьте сюда вызов API\n","    return response_text"]},{"cell_type":"markdown","metadata":{"id":"8YH9vpXgYWgE"},"source":["2. Используйте self-reflection для 5 задач из задачи 2 (CoT) и сравните результаты до и после рефлексии.\n","3. Ответьте на вопросы:\n","   - Улучшаются ли ответы?\n","   - Исправляет ли модель правильные ответы на неправильные?"]},{"cell_type":"markdown","metadata":{"id":"DmQL33ulbKCQ"},"source":["## Задача 5: Защита от инъекций (10 баллов)\n","\n"," Исследуйте методы защиты от инъекций в пользовательских вводах.\n"]},{"cell_type":"markdown","metadata":{"id":"MD1UespxbMRP"},"source":["1. Реализуйте функцию, которая проверяет ввод пользователя на наличие потенциальных инъекций:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d3FZm9MbW_H"},"outputs":[],"source":["import re\n","\n","# Функция проверки на инъекцию\n","def detect_injection(user_input: str) -> bool:\n","    \"\"\"\n","    Проверяет текст на наличие возможных инъекций.\n","    Возвращает True, если найдена инъекция.\n","    \"\"\"\n","    # Примеры подозрительных шаблонов\n","    injection_patterns = [\n","        r\"ignore.*instructions\",  # Игнорировать инструкции\n","        r\"forget.*previous\",      # Забыть предыдущие команды\n","        r\"reveal.*secret\",        # Раскрыть секрет\n","        r\"break.*rules\",          # Нарушить правила\n","    ]\n","    for pattern in injection_patterns:\n","        if re.search(pattern, user_input, re.IGNORECASE):\n","            return ...\n","    return False\n","\n","# Пример использования\n","def process_user_input(user_input: str) -> str:\n","    \"\"\"\n","    Обрабатывает пользовательский ввод с проверкой на инъекции.\n","    \"\"\"\n","    if detect_injection(user_input):\n","        return \"Ошибка: обнаружена потенциальная инъекция!\"\n","\n","    # Если инъекций нет, отправляем запрос к модели\n","    data = {\n","        \"model\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n","        \"prompt\": user_input,\n","        \"max_tokens\": 50\n","    }\n","    response = requests.post(url, headers=headers, json=data)\n","    if response.status_code == 200:\n","        return json.loads(response.text)[\"choices\"][0][\"text\"].strip()\n","    else:\n","        return f\"Ошибка: {response.status_code}\"\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aUQWALxpbMyy"},"source":["2. Протестируйте функцию на 5 различных вводах, включая как корректные запросы, так и попытки инъекций.\n","3. Напишите выводы о том, как система справляется с защитой и какие улучшения можно внести."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFEtFmuzbiZ5"},"outputs":[],"source":["# Тестирование\n","inputs = [\n","    \"What is the capital of France?\",\n","    ...\n","]\n","\n","for i, inp in enumerate(inputs):\n","    print(f\"Input {i+1}: {inp}\")\n","    print(f\"Output: {process_user_input(inp)}\")\n","    print(\"-\" * 40)"]},{"cell_type":"markdown","metadata":{"id":"6j1lMDpIYbZi"},"source":["## Требования к оформлению\n","- Каждый результат должен быть сопровожден кодом, комментариями и выводами.\n","- Предоставьте accuracy, сравнения и выводы в формате markdown в jupyter notebook."]},{"cell_type":"markdown","metadata":{"id":"hMFfpIc5Yh_k"},"source":["## Дополнительное задание (по желанию, +5 баллов)\n","Проверьте, как работает модель с разными длинами промпта (от коротких до детализированных). Как длина промпта влияет на качество ответа?\n","\n","---\n","\n","**Удачи в выполнении задания!**\n"]},{"cell_type":"markdown","metadata":{"id":"gqvAlTKWCXAP"},"source":["P.S. перед сдачей задания не забудьте удалить свой ключ от together из ноутбука!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}