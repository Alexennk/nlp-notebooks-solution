{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad5cc03",
   "metadata": {
    "papermill": {
     "duration": 0.015795,
     "end_time": "2025-02-04T15:20:34.216299",
     "exception": false,
     "start_time": "2025-02-04T15:20:34.200504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Задание 3\n",
    "\n",
    "В этом задании мы напишем архитектуру transformer с нуля. Мы пройдемся по всем слоям трансформера - от эмбеддингов и аттеншена до FFN и финального выходного слоя. В конце также напишем различные техники сэмплирования для генерации текста!\n",
    "\n",
    "\n",
    "В качестве весов мы будем использовать веса gpt2, однако уже в следующем задании попробуем обучить свой мини-трансформер с нуля!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3273836",
   "metadata": {
    "id": "xnqvoOGqZ2oX",
    "papermill": {
     "duration": 0.013986,
     "end_time": "2025-02-04T15:20:34.244469",
     "exception": false,
     "start_time": "2025-02-04T15:20:34.230483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Устанавливаем зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465d1774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:20:34.275961Z",
     "iopub.status.busy": "2025-02-04T15:20:34.275598Z",
     "iopub.status.idle": "2025-02-04T15:21:04.249355Z",
     "shell.execute_reply": "2025-02-04T15:21:04.248071Z"
    },
    "id": "DcuFItWyPbey",
    "outputId": "b0000c9b-9a0d-4eca-a32c-c9ce7e3f4df3",
    "papermill": {
     "duration": 29.992523,
     "end_time": "2025-02-04T15:21:04.251039",
     "exception": false,
     "start_time": "2025-02-04T15:20:34.258516",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer_lens\r\n",
      "  Downloading transformer_lens-2.11.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.2.1)\r\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\r\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\r\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\r\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (3.2.0)\r\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\r\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\r\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\r\n",
      "Collecting jaxtyping>=0.2.11 (from transformer_lens)\r\n",
      "  Downloading jaxtyping-0.2.37-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.2.2)\r\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.9.4)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.0)\r\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.67.1)\r\n",
      "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.47.0)\r\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.4.1)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\r\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.19.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.27.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.9.0)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.10)\r\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\r\n",
      "  Downloading wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24->transformer_lens) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.21.0)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.10.3)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.19.2)\r\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.4)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.2.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.12.14)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->transformer_lens) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24->transformer_lens) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->transformer_lens) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24->transformer_lens) (2024.2.0)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24->transformer_lens) (2024.2.0)\r\n",
      "Downloading transformer_lens-2.11.0-py3-none-any.whl (177 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\r\n",
      "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\r\n",
      "Downloading jaxtyping-0.2.37-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: better-abc, wadler-lindig, fancy-einsum, beartype, jaxtyping, transformer_lens\r\n",
      "Successfully installed beartype-0.14.1 better-abc-0.0.3 fancy-einsum-0.0.3 jaxtyping-0.2.37 transformer_lens-2.11.0 wadler-lindig-0.1.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.37)\r\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (0.1.3)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\r\n",
      "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-odi9219q\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-odi9219q\r\n",
      "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\r\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.26.4)\r\n",
      "Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.21.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0,>=1.23->circuitsvis==0.0.0) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2024.9.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.23->circuitsvis==0.0.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0,>=1.23->circuitsvis==0.0.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.23->circuitsvis==0.0.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0,>=1.23->circuitsvis==0.0.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0,>=1.23->circuitsvis==0.0.0) (2024.2.0)\r\n",
      "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\r\n",
      "Building wheels for collected packages: circuitsvis\r\n",
      "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6220038 sha256=0d84eef482b8d298a54351057a5cca4fe47b26a80dffa934fafc3e8149238571\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gg9fjubo/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\r\n",
      "Successfully built circuitsvis\r\n",
      "Installing collected packages: importlib-metadata, circuitsvis\r\n",
      "  Attempting uninstall: importlib-metadata\r\n",
      "    Found existing installation: importlib_metadata 8.5.0\r\n",
      "    Uninstalling importlib_metadata-8.5.0:\r\n",
      "      Successfully uninstalled importlib_metadata-8.5.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "opentelemetry-api 1.29.0 requires importlib-metadata<=8.5.0,>=6.0, but you have importlib-metadata 5.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformer_lens\n",
    "%pip install einops\n",
    "%pip install jaxtyping\n",
    "%pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341a0ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:04.285442Z",
     "iopub.status.busy": "2025-02-04T15:21:04.285175Z",
     "iopub.status.idle": "2025-02-04T15:21:44.816623Z",
     "shell.execute_reply": "2025-02-04T15:21:44.815296Z"
    },
    "id": "bAVtXXZiPJlr",
    "outputId": "58e02951-e34a-4015-a477-61efa0229d58",
    "papermill": {
     "duration": 40.550707,
     "end_time": "2025-02-04T15:21:44.818492",
     "exception": false,
     "start_time": "2025-02-04T15:21:04.267785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca39ecdeda2475b881053e093283044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c05275dc1451f9bd81695a213af81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1a98d408074fc4b0d19a0cca182c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6187f90cadb94417a2222807faf84794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0687438c47da46cba70d4ec5d03088cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52267ba9decb4ae6a9eb21bb9391758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea30c88dd5854a4c8e52ec6b22d45af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import os; os.environ['ACCELERATE_DISABLE_RICH'] = \"1\"\n",
    "import einops\n",
    "from dataclasses import dataclass\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch as t\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from jaxtyping import Float, Int\n",
    "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Загружаем веса gpt2 для проверки\n",
    "reference_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)\n",
    "reference_gpt2 = reference_gpt2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09db862",
   "metadata": {
    "papermill": {
     "duration": 0.018584,
     "end_time": "2025-02-04T15:21:44.856509",
     "exception": false,
     "start_time": "2025-02-04T15:21:44.837925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Конфиг, который хранит в себе всю информацию о размерностях модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68519579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:44.893939Z",
     "iopub.status.busy": "2025-02-04T15:21:44.893542Z",
     "iopub.status.idle": "2025-02-04T15:21:44.899051Z",
     "shell.execute_reply": "2025-02-04T15:21:44.898242Z"
    },
    "id": "XjdS6H9pO9E0",
    "outputId": "d969637c-358d-43c6-d179-db31132d6e1e",
    "papermill": {
     "duration": 0.025375,
     "end_time": "2025-02-04T15:21:44.900641",
     "exception": false,
     "start_time": "2025-02-04T15:21:44.875266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768 # он же hidden_dim - внутрення размерность модели\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5 \n",
    "    d_vocab: int = 50257 # он же vocab_size, размер словаря модели\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024 # число позиционных эмбеддингов; получается, что и длина контекста\n",
    "    d_head: int = 64 # размерность головы аттеншена\n",
    "    d_mlp: int = 3072 # внутренняя размерность FFN-слоя\n",
    "    n_heads: int = 12 # число голов аттеншена\n",
    "    n_layers: int = 12 # число слоев трансформера\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bde379",
   "metadata": {
    "papermill": {
     "duration": 0.018031,
     "end_time": "2025-02-04T15:21:44.936368",
     "exception": false,
     "start_time": "2025-02-04T15:21:44.918337",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Код для генерации тестов, которые мы будем использовать для проверки слоев!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b0b204a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:44.970850Z",
     "iopub.status.busy": "2025-02-04T15:21:44.970506Z",
     "iopub.status.idle": "2025-02-04T15:21:44.977194Z",
     "shell.execute_reply": "2025-02-04T15:21:44.976117Z"
    },
    "id": "ctCDi2ccPx-H",
    "papermill": {
     "duration": 0.025511,
     "end_time": "2025-02-04T15:21:44.978631",
     "exception": false,
     "start_time": "2025-02-04T15:21:44.953120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_float_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg).to(device)\n",
    "    random_input = torch.randn(shape).to(device)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    if isinstance(output, tuple): output = output[0]\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg).to(device)\n",
    "    random_input = torch.randint(100, 1000, shape).to(device)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    if isinstance(output, tuple): output = output[0]\n",
    "    print(\"Output shape:\", output.shape, \"\\n\")\n",
    "\n",
    "def load_gpt2_test(cls, gpt2_layer, input):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg).to(device)\n",
    "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
    "    print(\"Input shape:\", input.shape)\n",
    "    output = layer(input)\n",
    "    if isinstance(output, tuple): output = output[0]\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    try: reference_output = gpt2_layer(input)\n",
    "    except: reference_output = gpt2_layer(input, input, input)\n",
    "    print(\"Reference output shape:\", reference_output.shape, \"\\n\")\n",
    "    comparison = t.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
    "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d74a747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:45.014350Z",
     "iopub.status.busy": "2025-02-04T15:21:45.014088Z",
     "iopub.status.idle": "2025-02-04T15:21:45.026506Z",
     "shell.execute_reply": "2025-02-04T15:21:45.025301Z"
    },
    "id": "oSNvnHYaQrqZ",
    "outputId": "8f6eca33-9869-4324-e355-8e1bc3d3002a",
    "papermill": {
     "duration": 0.032813,
     "end_time": "2025-02-04T15:21:45.028510",
     "exception": false,
     "start_time": "2025-02-04T15:21:44.995697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
      "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
      "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
      "          1011,   625,   262,   995,     0]])\n",
      "torch.Size([1, 35])\n",
      "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text).to(device)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.to_str_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0f3f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:45.065020Z",
     "iopub.status.busy": "2025-02-04T15:21:45.064667Z",
     "iopub.status.idle": "2025-02-04T15:21:45.341671Z",
     "shell.execute_reply": "2025-02-04T15:21:45.340249Z"
    },
    "id": "6iN1wz9mUNTY",
    "outputId": "7fc249d2-88e3-4238-e851-c5e71d36f086",
    "papermill": {
     "duration": 0.29724,
     "end_time": "2025-02-04T15:21:45.343388",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.046148",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 35, 50257])\n",
      "Все работает, мы готовы к выполнению задания!\n"
     ]
    }
   ],
   "source": [
    "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
    "print(logits.shape)\n",
    "\n",
    "print(\"Все работает, мы готовы к выполнению задания!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05c3b1",
   "metadata": {
    "papermill": {
     "duration": 0.016642,
     "end_time": "2025-02-04T15:21:45.377222",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.360580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Архитектура Transformer - 40 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6c68a",
   "metadata": {
    "id": "7kIRmiHZ87sw",
    "papermill": {
     "duration": 0.017766,
     "end_time": "2025-02-04T15:21:45.412156",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.394390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Embeddings - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c5004",
   "metadata": {
    "papermill": {
     "duration": 0.016298,
     "end_time": "2025-02-04T15:21:45.444814",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.428516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Здесь нам даются токены размерности `[batch_size, seq_len]` - индексы слов в словаре. Нужно описать слой Embed, который будет отображать каждый токен в соответствующий вектор из матрицы эмбеддингов. Таким образом каждому токену предоставляется вектор, который будет иметь размерности `[batch_size, seq_len, d_model]`\n",
    "\n",
    "Внимание - здесь не нужно исользовать цикл for и проходиться по матрице. Все стандартные операции доступны в [документации](https://pytorch.org/docs/stable/nn.functional.html), в частности тут нам понадобится одна из операций в секции [sparse functions](https://pytorch.org/docs/stable/nn.functional.html#sparse-functions).\n",
    "\n",
    "Важное замечание - на самом деле этот слой уже есть [готовый в pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html), но мы в учебных целях переписываем его сами.\n",
    "\n",
    "\n",
    "Также можно решить этот пример через индексацию или через einops.\n",
    "\n",
    "**Вообще почти во всех примерах есть несколько возможных стилей описания операций над тензорами - через torch.nn.functional, через различные индексации и трюки pytorch, через einops - можно делать любым удобным способом!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb682b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:45.480606Z",
     "iopub.status.busy": "2025-02-04T15:21:45.480330Z",
     "iopub.status.idle": "2025-02-04T15:21:45.485075Z",
     "shell.execute_reply": "2025-02-04T15:21:45.484215Z"
    },
    "id": "srX7Xj8FaMHX",
    "outputId": "3387370e-0710-4c15-b76d-091dc7ef34a8",
    "papermill": {
     "duration": 0.024663,
     "end_time": "2025-02-04T15:21:45.486142",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.461479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        pass\n",
    "        return nn.functional.embedding(input_ids, self.W_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b84bb908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:45.519960Z",
     "iopub.status.busy": "2025-02-04T15:21:45.519649Z",
     "iopub.status.idle": "2025-02-04T15:21:46.087703Z",
     "shell.execute_reply": "2025-02-04T15:21:46.086680Z"
    },
    "papermill": {
     "duration": 0.586439,
     "end_time": "2025-02-04T15:21:46.089194",
     "exception": false,
     "start_time": "2025-02-04T15:21:45.502755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "rand_int_test(Embed, [batch_size, seq_len])\n",
    "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0dbf78",
   "metadata": {
    "papermill": {
     "duration": 0.016564,
     "end_time": "2025-02-04T15:21:46.122962",
     "exception": false,
     "start_time": "2025-02-04T15:21:46.106398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Positional Embeddings - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02beae2a",
   "metadata": {
    "papermill": {
     "duration": 0.017215,
     "end_time": "2025-02-04T15:21:46.157398",
     "exception": false,
     "start_time": "2025-02-04T15:21:46.140183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "В трансформерах есть не только обычные эмбеддинги, которые отвечают за \"смысл\" токенов, но и позиционные эмбеддинги! Вход у них такой же, как и у обычных эмбеддингов, только они должны эмбеддить позиции токенов, а не сами токены. Т.е. в матрице W_pos хранятся не эмбеддинги токенов, а эмбеддинги позиций.\n",
    "\n",
    "Поэтому в этом слое нужно:\n",
    "1. По tokens получить тензор positions размера `[batch_size, seq_len]`\n",
    "2. Заэмбеддить тензор positions, как в предыдущем слое.\n",
    "\n",
    "Важно - как и в предыдущем случае, для этот слой обычно используется через [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "\n",
    "\n",
    "Вспомним еще про то, откуда берутся позиционные эмбеддинги: в оригинальном трансформере позиционные эмбеддинги состояли из синусов и косинусов (см. пункт 3.5 из оригинальной статьи https://arxiv.org/pdf/1706.03762), однако позиционные эмбеддинги можно учить и с нуля, как и обычные эмбеддинги. **В рамках данного задания не нужно никак дополнительно инициализировать веса, только применить позиционные эмбеддинги**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11abfa08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:46.247088Z",
     "iopub.status.busy": "2025-02-04T15:21:46.246747Z",
     "iopub.status.idle": "2025-02-04T15:21:46.267665Z",
     "shell.execute_reply": "2025-02-04T15:21:46.266536Z"
    },
    "id": "trB2m2P8Rgrk",
    "outputId": "1405f0c5-586f-42aa-eb77-6ada974b74e3",
    "papermill": {
     "duration": 0.094803,
     "end_time": "2025-02-04T15:21:46.269201",
     "exception": false,
     "start_time": "2025-02-04T15:21:46.174398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0).expand(batch_size, -1)  # (batch_size, seq_len)\n",
    "        return nn.functional.embedding(positions, self.W_pos)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "rand_int_test(PosEmbed, [batch_size, seq_len])\n",
    "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745749a3",
   "metadata": {
    "papermill": {
     "duration": 0.017394,
     "end_time": "2025-02-04T15:21:46.304631",
     "exception": false,
     "start_time": "2025-02-04T15:21:46.287237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM head - 5 баллов\n",
    "\n",
    "Финальный слой. У нас есть выходы из трансформера размерности `[batch_size, seq_len, d_model]`. Это контекстуализированные представления каждого токена. По ним мы предсказываем следующий токен, т.е. применяем линейный слой - умножаем на матрицу `[d_model, vocab_size]`.\n",
    "\n",
    "В этом нам поможет секция [linear functions](https://pytorch.org/docs/stable/nn.functional.html#linear-functions). Не забудьте про bias!\n",
    "\n",
    "В pytorch этот слой тоже есть - [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fdbfa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:46.342495Z",
     "iopub.status.busy": "2025-02-04T15:21:46.342207Z",
     "iopub.status.idle": "2025-02-04T15:21:47.019584Z",
     "shell.execute_reply": "2025-02-04T15:21:47.018414Z"
    },
    "id": "XLXcAsSMU58C",
    "outputId": "f12c9d13-f3bf-477b-bdd0-a40a3ccad998",
    "papermill": {
     "duration": 0.699027,
     "end_time": "2025-02-04T15:21:47.021171",
     "exception": false,
     "start_time": "2025-02-04T15:21:46.322144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 50257]) \n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 50257])\n",
      "Reference output shape: torch.Size([1, 35, 50257]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LM_head, но для совместимости с библиотекой для проверки пришлось назвать его Unembed\n",
    "# по аналогии с тем, что мы из индексов в словаре получаем эмбеддинги, а тут из эмбеддингов обратно\n",
    "# распределение по словарю\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        return nn.functional.linear(x, t.transpose(self.W_U, 0, 1), self.b_U)\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 768\n",
    "rand_float_test(Unembed, [batch_size, seq_len, d_model])\n",
    "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37f4b4",
   "metadata": {
    "papermill": {
     "duration": 0.017149,
     "end_time": "2025-02-04T15:21:47.056860",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.039711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa78cbc",
   "metadata": {
    "id": "UfxZG2l7A-wQ",
    "papermill": {
     "duration": 0.017039,
     "end_time": "2025-02-04T15:21:47.091096",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.074057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention-формулы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee994fc1",
   "metadata": {
    "id": "30Q7cmNtFudx",
    "papermill": {
     "duration": 0.017936,
     "end_time": "2025-02-04T15:21:47.126595",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.108659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Входные эмбеддинги**:\n",
    "   $$X \\in \\mathbb{R}^{seq \\times d} $$\n",
    "2. **Маскированный мультихед-аттеншен (Masked Multi-Head Attention)**:\n",
    "$$M = \\begin{cases}\n",
    " &  m_{ij} = -\\infty, \\quad i < j \\\\\n",
    " &  m_{ij} = 0\n",
    "\\end{cases} $$\n",
    "\n",
    "$$\n",
    "M = \\begin{pmatrix}\n",
    "0 & -\\infty & -\\infty & \\ldots & -\\infty \\\\\n",
    "0 & 0 & -\\infty & \\ldots & -\\infty \\\\\n",
    "0 & 0 & 0 & \\ldots & -\\infty \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\ldots & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bda06",
   "metadata": {
    "id": "-FwfAHyzQ1Bs",
    "papermill": {
     "duration": 0.017544,
     "end_time": "2025-02-04T15:21:47.161739",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.144195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "3. Для каждой головы $ h_i $:\n",
    "\n",
    "    3.1 **Матрицы весов для запросов, ключей и значений**:\n",
    "     - $ W_Q \\in \\mathbb{R}^{d \\times d_h} $\n",
    "     - $ W_K \\in \\mathbb{R}^{d \\times d_h} $\n",
    "     - $ W_V \\in \\mathbb{R}^{d \\times d_h} $\n",
    "     \n",
    "    3.2. **Запросы, ключи и значения**:\n",
    "     - $ Q = X W_Q \\in \\mathbb{R}^{seq \\times d_h} $\n",
    "     - $ K = X W_K \\in \\mathbb{R}^{seq \\times d_h} $\n",
    "     - $ V = X W_V \\in \\mathbb{R}^{seq \\times d_h} $\n",
    "\n",
    "    3.3. **Скалярные произведения запросов и ключей**:\n",
    "     - $ \\frac{Q K^T}{\\sqrt{d_h}} + M \\in \\mathbb{R}^{seq \\times seq} $\n",
    "\n",
    "    3.4. **Веса внимания**:\n",
    "     - $ \\alpha = \\text{softmax}\\left(\\frac{Q K^T}{\\sqrt{d_h}} + M\\right) \\in \\mathbb{R}^{seq \\times seq} $\n",
    "\n",
    "    3.5. **Агрегация значений**:\n",
    "     - $ z = \\alpha V \\in \\mathbb{R}^{seq \\times d_h} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049f60c",
   "metadata": {
    "id": "EEuVgMeMR6ce",
    "papermill": {
     "duration": 0.017068,
     "end_time": "2025-02-04T15:21:47.197437",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.180369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "4. **Конкатенация выходов всех голов**:\n",
    "   - $ Z = \\text{Concat}(z_1, z_2, \\ldots, z_h) \\in \\mathbb{R}^{seq \\times d} $\n",
    "\n",
    "5. **Выходной линейный слой**:\n",
    "   - Матрица весов: $ W^O \\in \\mathbb{R}^{d \\times d} $\n",
    "   - Итоговый выход: $ O = Z W^O + X \\in \\mathbb{R}^{seq \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297737b",
   "metadata": {
    "papermill": {
     "duration": 0.017813,
     "end_time": "2025-02-04T15:21:47.232644",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.214831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Attention - детали реализации\n",
    "Самое сложное в этом домашнем задании - подсчет механизма внимания. Как и в предыдущих вариантах, считать можно через torch или с помощью einops и любыми другими удобными способами.\n",
    "\n",
    "\n",
    "В данном задании нужно реализовать multihead attention с маскированием. Давайте разбираться по шагам, что нам нужно сделать.\n",
    "\n",
    "Далее будет описан один из возможных алогритмов написания аттеншена, но повторимся - писать можно любым удобным способом (голый torch или einops).\n",
    "\n",
    "1. Нам попадает на вход вектор x `[batch, seq_len, d_model]`. Нужно превратить его в матрицы проекций i-й головы аттеншена: Q_i, K_i, V_i. Для этого у нас есть матрицы W_Q, W_K, W_V (и их bias!). Это набор n_heads матриц размеров `[d_model, d_head]`. Зачастую число голов n_head и d_head подобраны так, что d_model == n_head * d_head, наш случай не исключение. Предлагается перевести (этот шаг сделан) матрицу `[num_heads, d_model, d_head]` в матрицу `[d_model, num_heads * d_head]` = `[d_model, d_model]`, после чего получить через матричное умножение на X размерности `[batch_size, seq_len, d_model]` получить матрицы Q, K, V размерностей `[batch_size, seq_len, d_model] = [batch_size, seq_len, num_heads * d_head]` и преобразовать их к виду `[batch_size, seq_len, num_heads, d_head]`. Не забудьте при матричном умножении транспонировать матрицы W_Q, W_K, W_V, если пойдете этим путем! В качестве шпаргалки посмотрите, как происходило умножение в lm_head!\n",
    "\n",
    "2. После этого можно сделать первый шаг и посчитать attention_scores, т.е. домножить $Q \\times K^T$. Тут нам поможет .transpose или .permute вместе с torch.matmul. Нужно переставить размерности матриц таким образом, чтобы финальное матричное умножение происходило по двум последним размерностям `[seq_len, d_head]` на `[d_head, seq_len]`, а все предыдущие размерности `[batch_size, num_heads]` совпадали\n",
    "\n",
    "\n",
    "3. Не забудем нормализацию, т.е. делим attention_scores на sqrt(d_head)\n",
    "\n",
    "4. Теперь нужно исползьовать маскирование! В данных заданиях предполагается, что у нас нет паддингов, поэтому нам нужно наложить маску с одним простым условием: i-й элемент не может смотреть на j-й элемент, если j > i. Это треугольная маска, с ней нам поможет приведение треугольной форме, которое вам предлагается найти в pytorch! Замаскированные значения нужно заполнить каким-нибудь большим по модулю отрицательным числом В классе уже опредеелно значение IGNORE, можно использовать его. Для этого реализуйте и используйте функцию `apply_causal_mask`. Заполнять значениями можно через индексацию, например через `torch.masked_fill`.\n",
    "\n",
    "5. Теперь к замаскированным attention_scores `[batch_size, num_heads, seq_len, seq_len]` нужно применить softmax. Подумайте, по какой размерности его применять и на что это повлияет.\n",
    "\n",
    "6. После этого остается последнее матричное умножение softmax(attention_scores) на V, к которому тоже придется применить .view, .permute и torch.matmul\n",
    "\n",
    "7. Теперь, если вы следовали этому плану у вас остается матрица `ouput` размерностей `[batch_size, num_heads, seq_len, d_head]`. С помощью permute и view собираем (конкатенируем) ее обратно в матрицу `[batch_size, seq_len, num_heads * d_head] = [batch_size, seq_len, d_model]` и применяем к ней выходной линейный слой W_O. Всё, аттеншен готов!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75c49009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:47.269238Z",
     "iopub.status.busy": "2025-02-04T15:21:47.268953Z",
     "iopub.status.idle": "2025-02-04T15:21:47.333930Z",
     "shell.execute_reply": "2025-02-04T15:21:47.332877Z"
    },
    "id": "65yvUiIvTbTk",
    "outputId": "65effb74-04d4-4e74-b7b5-a961075de222",
    "papermill": {
     "duration": 0.08541,
     "end_time": "2025-02-04T15:21:47.335628",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.250218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    IGNORE: Float[Tensor, \"\"]\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
    "        \n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        \n",
    "        # Берем размерности\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        num_heads = self.cfg.n_heads\n",
    "        d_head = self.cfg.d_head\n",
    "        \n",
    "        # 1. Трансформируем матрицы проекций в формат [d_model, d_model]\n",
    "        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_O = self.W_O.reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        \n",
    "        b_Q = self.b_Q.view(-1)\n",
    "        b_K = self.b_K.view(-1)\n",
    "        b_V = self.b_V.view(-1)\n",
    "        \n",
    "        # 1. получаем проекции  Q, K, V\n",
    "        Q = t.matmul(x, W_Q) + b_Q\n",
    "        K = t.matmul(x, W_K) + b_K\n",
    "        V = t.matmul(x, W_V) + b_V\n",
    "        \n",
    "        # 1.5. Привести к размерностям [batch_size, seq_len, num_heads, d_head]\n",
    "        Q = Q.view(batch_size, seq_len, num_heads, d_head)\n",
    "        K = K.view(batch_size, seq_len, num_heads, d_head)\n",
    "        V = V.view(batch_size, seq_len, num_heads, d_head)\n",
    "        \n",
    "        # 2. Q x K^T\n",
    "        # Привести к [batch_size, num_heads, seq_len, d_head]\n",
    "        Q = Q.permute(0, 2, 1, 3)  # [batch_size, num_heads, seq_len, d_head]\n",
    "        K = K.permute(0, 2, 1, 3)  # [batch_size, num_heads, seq_len, d_head]\n",
    "        V = V.permute(0, 2, 1, 3)  # [batch_size, num_heads, seq_len, d_head]\n",
    "\n",
    "        attn_scores = t.matmul(Q, K.transpose(-1, -2)) # [batch_size, num_heads, seq_len, seq_len]\n",
    "        \n",
    "        # 3. Нормализация\n",
    "        attn_scores = attn_scores / t.sqrt(t.tensor(d_head, dtype=t.float32, device=x.device))\n",
    "        \n",
    "        # 4. Маскирование\n",
    "        attn_scores = self.apply_causal_mask(attn_scores)\n",
    "        \n",
    "        # 5. softmax\n",
    "        attn_probs = nn.functional.softmax(attn_scores, dim=-1) # [batch_size, num_heads, seq_len, seq_len]\n",
    "\n",
    "        # 6. Финальная проекция\n",
    "        attn_output = t.matmul(attn_probs, V) # [batch_size, num_heads, seq_len, d_head]\n",
    "\n",
    "        # 7. Собрать матрицу [batch_size, seq_len, d_model]\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3)\n",
    "        attn_output = attn_output.contiguous().view(batch_size, seq_len, -1)\n",
    "\n",
    "        # 8. Умножить на W_O\n",
    "        output = t.matmul(attn_output, W_O) + self.b_O\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "    def apply_causal_mask(\n",
    "        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n",
    "        '''\n",
    "        Используем треугольную маску, чтобы не смотреть в будущее, паддингов нет\n",
    "        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n",
    "        '''\n",
    "        seq_len = attn_scores.shape[-1]\n",
    "        mask = t.triu(t.ones((seq_len, seq_len), device=attn_scores.device), diagonal=1)\n",
    "        attn_scores = attn_scores.masked_fill(mask == 1, self.IGNORE)\n",
    "        return attn_scores\n",
    "\n",
    "torch.manual_seed(1)\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 768\n",
    "rand_float_test(Attention, [batch_size, seq_len, d_model])\n",
    "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14481a7",
   "metadata": {
    "papermill": {
     "duration": 0.01733,
     "end_time": "2025-02-04T15:21:47.371480",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.354150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Если вы справились с этим, то поздравляю - ничего сложнее мы сегодня уже не будем делать)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e705d4c",
   "metadata": {
    "id": "anGg23a4_aTy",
    "papermill": {
     "duration": 0.017528,
     "end_time": "2025-02-04T15:21:47.406813",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.389285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLP (или FFN в других терминологиях) - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31447c7",
   "metadata": {
    "id": "BRLuXGJb6NT2",
    "papermill": {
     "duration": 0.017137,
     "end_time": "2025-02-04T15:21:47.442448",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.425311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Реализуем MLP слой - это 2 матричных умножения с нелинейностью GELU.\n",
    "\n",
    "- $$ \\text{MLP}(X) = (\\text{GeLU}(X W_1 + b_1)) W_2 + b_2 \\in \\mathbb{R}^{\\text{seq} \\times d}$$\n",
    "-    $$W_1 \\in \\mathbb{R}^{d \\times d_{mlp}}, \\quad b_1 \\in \\mathbb{R}^{d_{mlp}} \\\\\n",
    "W_2 \\in \\mathbb{R}^{d_{mlp} \\times d}, \\quad b_2 \\in \\mathbb{R}^{d} \\\\ $$\n",
    "\n",
    "\n",
    "$$GELU(X) = 0.5 * x * (1 + tanh(\\sqrt {\\frac {2} {\\pi}} * (x + 0.44715 * x^3)))$$\n",
    "\n",
    "если будете использовать gelu из pytorch, то **обязательно** проставьте approximate=\"tanh\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21d8205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:47.478661Z",
     "iopub.status.busy": "2025-02-04T15:21:47.478264Z",
     "iopub.status.idle": "2025-02-04T15:21:47.572205Z",
     "shell.execute_reply": "2025-02-04T15:21:47.571297Z"
    },
    "id": "0hQCIDevT0h3",
    "outputId": "069564c9-b46c-43ea-e4e3-a37162a03882",
    "papermill": {
     "duration": 0.113452,
     "end_time": "2025-02-04T15:21:47.573388",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.459936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
    "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        output_1 = nn.functional.gelu(t.matmul(x, self.W_in) + self.b_in, approximate=\"tanh\")\n",
    "        output = t.matmul(output_1, self.W_out) + self.b_out\n",
    "        return output\n",
    "\n",
    "        \n",
    "torch.manual_seed(1)\n",
    "\n",
    "rand_float_test(MLP, [batch_size, seq_len, d_model])\n",
    "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"normalized\", 0, \"ln2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964023a",
   "metadata": {
    "id": "SVAp7w1gR8tU",
    "papermill": {
     "duration": 0.017778,
     "end_time": "2025-02-04T15:21:47.609138",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.591360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Normalization - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e066e6",
   "metadata": {
    "id": "-aM9JUorIwwj",
    "papermill": {
     "duration": 0.017482,
     "end_time": "2025-02-04T15:21:47.645582",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.628100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Layer Normalization**:\n",
    "   - $ \\text{LayerNorm}(X) = \\frac{X - \\mu}{\\sigma} \\cdot \\gamma + \\beta $\n",
    "   - $\\mu = \\text{mean}(X, \\text{dim}=-1) \\in \\mathbb{R}^{d}$\n",
    "   - $\\sigma = \\sqrt{\\text{var}(X, \\text{dim}=-1) + \\epsilon} \\in \\mathbb{R}^{d}$\n",
    "   - $\\gamma \\in \\mathbb{R}^{d}$\n",
    "   - $\\beta \\in \\mathbb{R}^{d}$\n",
    "   \n",
    "   \n",
    "1. Не забудьте про эпсилон, который хранится в cfg!\n",
    "2. В [подсчете дисперсии](https://pytorch.org/docs/stable/generated/torch.var.html) не используете коррекцию Бесселя! Для этого в зависимости от версии pytorch поставьте `unbiased=False` или `correction=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6aa98a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:47.682860Z",
     "iopub.status.busy": "2025-02-04T15:21:47.682518Z",
     "iopub.status.idle": "2025-02-04T15:21:47.698831Z",
     "shell.execute_reply": "2025-02-04T15:21:47.697900Z"
    },
    "id": "PnNVykkAP49l",
    "outputId": "eeef206b-fd72-4550-827f-f39652652c57",
    "papermill": {
     "duration": 0.036489,
     "end_time": "2025-02-04T15:21:47.700008",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.663519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(t.ones(cfg.d_model)) # gamma\n",
    "        self.b = nn.Parameter(t.zeros(cfg.d_model)) # beta\n",
    "\n",
    "    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        pass\n",
    "        mu = x.mean(dim=-1, keepdim=True)\n",
    "        sigma = t.sqrt(x.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps)\n",
    "        output = (x - mu) / sigma\n",
    "        output = output * self.w + self.b\n",
    "        return output\n",
    "\n",
    "\n",
    "rand_float_test(LayerNorm, [2, 4, 768])\n",
    "load_gpt2_test(LayerNorm, reference_gpt2.ln_final, cache[\"resid_post\", 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1b92b",
   "metadata": {
    "id": "d9RPPHidUzRB",
    "papermill": {
     "duration": 0.017204,
     "end_time": "2025-02-04T15:21:47.734623",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.717419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Block - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c97fd4",
   "metadata": {
    "papermill": {
     "duration": 0.017742,
     "end_time": "2025-02-04T15:21:47.771062",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.753320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Это блок трансформера, который получает на вход тензор x `[batch_size, seq_len, d_model]` и выдает тензор таких же размерностей. Блок GPT2 немного отличается от классического трансформера, который мы изучали на лекции.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GPT2 следует схеме PreLN, а \"классический\" трансформер схеме PostLN. **Реализовать нужно PreLN схему!**\n",
    "\n",
    "В PostLN схеме нормализация происходит после слоев attention и MLP, а в PreLN до них согласно иллюстрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60c98e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:47.807413Z",
     "iopub.status.busy": "2025-02-04T15:21:47.807115Z",
     "iopub.status.idle": "2025-02-04T15:21:47.927451Z",
     "shell.execute_reply": "2025-02-04T15:21:47.926330Z"
    },
    "id": "A7fEX6-8VRjV",
    "outputId": "49b095dc-8583-4f06-b39a-5ee08d8475c7",
    "papermill": {
     "duration": 0.140099,
     "end_time": "2025-02-04T15:21:47.928694",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.788595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768]) \n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        pass\n",
    "        x_norm_1 = self.ln1(x)\n",
    "        x_attn = self.attn(x_norm_1)\n",
    "        x_norm_2 = self.ln2(x_attn + x)\n",
    "        x_mlp = self.mlp(x_norm_2)\n",
    "        return (x_attn + x) + x_mlp\n",
    "\n",
    "\n",
    "rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce0600",
   "metadata": {
    "papermill": {
     "duration": 0.017087,
     "end_time": "2025-02-04T15:21:47.964701",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.947614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer - 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b6586",
   "metadata": {
    "papermill": {
     "duration": 0.017466,
     "end_time": "2025-02-04T15:21:48.000410",
     "exception": false,
     "start_time": "2025-02-04T15:21:47.982944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Собираем все в один большой трансформер.\n",
    "1. Применяем эмбеддинги и позиционные эмбеддинги, складываем результаты\n",
    "2. Прогоняем в цикле через все блоки трансформера\n",
    "3. Применяем финальную нормализацию и lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7901c6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:48.038908Z",
     "iopub.status.busy": "2025-02-04T15:21:48.038564Z",
     "iopub.status.idle": "2025-02-04T15:21:50.627367Z",
     "shell.execute_reply": "2025-02-04T15:21:50.626588Z"
    },
    "id": "HdbjvO9sVLrk",
    "outputId": "5038a7f1-cb31-4ca6-cf06-961169472c97",
    "papermill": {
     "duration": 2.610177,
     "end_time": "2025-02-04T15:21:50.629252",
     "exception": false,
     "start_time": "2025-02-04T15:21:48.019075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 50257]) \n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 50257])\n",
      "Reference output shape: torch.Size([1, 35, 50257]) \n",
      "\n",
      "100.00% of the values are correct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        x = self.embed(input_ids) + self.pos_embed(input_ids)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_final(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "rand_int_test(DemoTransformer, [2, 4])\n",
    "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1210bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:50.666990Z",
     "iopub.status.busy": "2025-02-04T15:21:50.666654Z",
     "iopub.status.idle": "2025-02-04T15:21:51.595293Z",
     "shell.execute_reply": "2025-02-04T15:21:51.594444Z"
    },
    "id": "RcNrSDzgVjQg",
    "papermill": {
     "duration": 0.949435,
     "end_time": "2025-02-04T15:21:51.596780",
     "exception": false,
     "start_time": "2025-02-04T15:21:50.647345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_gpt2 = DemoTransformer(Config(debug=False)).to(device)\n",
    "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
    "\n",
    "demo_logits = demo_gpt2(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953d0aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:51.634177Z",
     "iopub.status.busy": "2025-02-04T15:21:51.633866Z",
     "iopub.status.idle": "2025-02-04T15:21:51.639010Z",
     "shell.execute_reply": "2025-02-04T15:21:51.637899Z"
    },
    "id": "Rb2_gL9uVmPj",
    "outputId": "d2e534f6-f1b0-4c99-a2d7-ef7d781f9b78",
    "papermill": {
     "duration": 0.025272,
     "end_time": "2025-02-04T15:21:51.640555",
     "exception": false,
     "start_time": "2025-02-04T15:21:51.615283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DemoTransformer(\n",
       "  (embed): Embed()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (attn): Attention()\n",
       "      (ln2): LayerNorm()\n",
       "      (mlp): MLP()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm()\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ecba0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:51.679345Z",
     "iopub.status.busy": "2025-02-04T15:21:51.679026Z",
     "iopub.status.idle": "2025-02-04T15:21:51.684329Z",
     "shell.execute_reply": "2025-02-04T15:21:51.683531Z"
    },
    "id": "fkrsjh5SVpl3",
    "outputId": "b6f9b98e-3bbc-456b-a21c-f33c847b98a9",
    "papermill": {
     "duration": 0.026224,
     "end_time": "2025-02-04T15:21:51.685397",
     "exception": false,
     "start_time": "2025-02-04T15:21:51.659173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HookedTransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (pos_embed): PosEmbed()\n",
       "  (hook_pos_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (ln1): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): LayerNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a0c9e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:51.723231Z",
     "iopub.status.busy": "2025-02-04T15:21:51.722967Z",
     "iopub.status.idle": "2025-02-04T15:21:51.734530Z",
     "shell.execute_reply": "2025-02-04T15:21:51.733647Z"
    },
    "id": "dyiHpWcvV2mn",
    "outputId": "5cbc4e40-c5ec-4219-f8da-08fbb25b357f",
    "papermill": {
     "duration": 0.0322,
     "end_time": "2025-02-04T15:21:51.735694",
     "exception": false,
     "start_time": "2025-02-04T15:21:51.703494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg cross entropy loss: 4.5647\n",
      "Avg cross entropy loss for uniform distribution: 10.824905\n",
      "Avg probability assigned to correct token: 0.087911\n"
     ]
    }
   ],
   "source": [
    "def get_log_probs(\n",
    "    logits: Float[Tensor, \"batch posn d_vocab\"],\n",
    "    tokens: Int[Tensor, \"batch posn\"]\n",
    ") -> Float[Tensor, \"batch posn-1\"]:\n",
    "\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n",
    "    log_probs_for_tokens = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    return log_probs_for_tokens\n",
    "\n",
    "\n",
    "pred_log_probs = get_log_probs(demo_logits, tokens)\n",
    "print(f\"Avg cross entropy loss: {-pred_log_probs.mean():.4f}\")\n",
    "print(f\"Avg cross entropy loss for uniform distribution: {math.log(demo_gpt2.cfg.d_vocab):4f}\")\n",
    "print(f\"Avg probability assigned to correct token: {pred_log_probs.exp().mean():4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3133a9bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:21:51.773570Z",
     "iopub.status.busy": "2025-02-04T15:21:51.773288Z",
     "iopub.status.idle": "2025-02-04T15:22:15.443131Z",
     "shell.execute_reply": "2025-02-04T15:22:15.442252Z"
    },
    "id": "jFqu7OlPV685",
    "outputId": "ea78b4f5-c285-4fcc-9bf0-cd3ec943c829",
    "papermill": {
     "duration": 23.690613,
     "end_time": "2025-02-04T15:22:15.444388",
     "exception": false,
     "start_time": "2025-02-04T15:21:51.753775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb45308141148c8ae4deb5443ed58f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Perspective Vortex derives its picture of the whole Universe on the principle of the total perspective. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The\n"
     ]
    }
   ],
   "source": [
    "test_string = '''The Total Perspective Vortex derives its picture of the whole Universe on the principle of'''\n",
    "for i in tqdm(range(100)):\n",
    "    test_tokens = reference_gpt2.to_tokens(test_string).to(device)\n",
    "    demo_logits = demo_gpt2(test_tokens)\n",
    "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
    "\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24faee",
   "metadata": {
    "id": "wG0zGo4iJFMa",
    "papermill": {
     "duration": 0.01738,
     "end_time": "2025-02-04T15:22:15.479879",
     "exception": false,
     "start_time": "2025-02-04T15:22:15.462499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Сэмплирование - 10 баллов\n",
    "Теперь разберем различные техники сэмплирования. За каждую из функций `apply_temperature`, `apply_frequency_penalty`, `sample_basic`, `sample_top_k`, `sample_top_p` по 2 балла."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c0d32",
   "metadata": {
    "id": "dK5fbWLLWwSS",
    "papermill": {
     "duration": 0.01761,
     "end_time": "2025-02-04T15:22:15.515226",
     "exception": false,
     "start_time": "2025-02-04T15:22:15.497616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "1. **Temperature Sampling**:\n",
    "   - Применяется первым, поскольку изменение температуры изменяет масштабы логитов перед дальнейшими операциями.\n",
    "\n",
    "2. **Frequency Penalty**:\n",
    "   - Применяется следующим, чтобы учесть частоты токенов до того, как логиты будут обрезаны методами top-k или top-p.\n",
    "\n",
    "3. **Top-k Sampling**:\n",
    "   - Применяется после temperature sampling и frequency penalty, так как он отбирает фиксированное количество наиболее вероятных токенов.\n",
    "\n",
    "4. **Top-p (Nucleus Sampling)**:\n",
    "   - Применяется после top-k sampling, чтобы отфильтровать токены на основе совокупной вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa26e7",
   "metadata": {
    "id": "TgdKJfPfbR-J",
    "papermill": {
     "duration": 0.017885,
     "end_time": "2025-02-04T15:22:15.550849",
     "exception": false,
     "start_time": "2025-02-04T15:22:15.532964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Обозначим размер словаря для удобства $\\Sigma = vocab\\_size$\n",
    "\n",
    "Пусть $ \\text{logits} \\in \\mathbb{R}^{\\text{seq} \\times \\Sigma} $:\n",
    "\n",
    "1. **Temperature Sampling**:\n",
    "   $$\n",
    "   \\text{logits}'_{i,j} = \\frac{\\text{logits}_{i,j}}{T} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, |\\Sigma|]\n",
    "   $$\n",
    "\n",
    "2. **Frequency Penalty**:\n",
    "   $$\n",
    "   \\text{penalty}(t_j) = 1 + \\alpha \\cdot f(t_j) \\\\\n",
    "   \\text{logits}''_{i,j} = \\text{logits}'_{i,j} - \\text{penalty}(t_j) \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n",
    "%    \\text{logits}''_{i,j} = \\frac{\\text{logits}'_{i,j}}{\\text{penalty}(t_j)} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n",
    "   $$\n",
    "\n",
    "3. **Top-k Sampling**:\n",
    "   $$\n",
    "   top\\_k\\_indices_i = \\text{argtop-k}(\\text{logits}''_i, k) \\quad \\forall \\ i \\in [1, \\text{seq}] \\\\\n",
    "   \\text{mask}_{i,j} =\n",
    "   \\begin{cases}\n",
    "   1 & \\text{если} \\ j \\in top\\_k\\_indices_i \\\\\n",
    "   0 & \\text{иначе}\n",
    "   \\end{cases} \\\\\n",
    "   \\text{logits}'''_{i,j} = \\text{logits}''_{i,j} \\cdot \\text{mask}_{i,j} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n",
    "   $$\n",
    "\n",
    "4. **Top-p (Nucleus Sampling)**:\n",
    "   $$\n",
    "   sorted\\_logits_i, sorted\\_indices_i = \\text{sort}(\\text{logits}'''_i, \\text{descending=True}) \\quad ∀ \\ i \\in [1, \\text{seq}] \\\\\n",
    "   probs_i = softmax(sorted\\_logits_i) \\quad \\\\\n",
    "    cumulative\\_probs_{i,j} = \\sum_{k=1}^{j} \\text{probs}_{i,k} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma\n",
    "    \\quad \\forall \\ i \\in [1, \\text{seq}] \\\\\n",
    "   top\\_p\\_mask_{i,j} =\n",
    "   \\begin{cases}\n",
    "   1, & cumulative\\_probs_{i,j} \\leq p \\\\\n",
    "   0 &\n",
    "   \\end{cases} \\\\\n",
    "   \\text{logits}^{\\text{final}}_{i,j} = sorted\\_logits_{i,j} \\cdot top\\_p\\_mask_{i,j} \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, \\Sigma]\n",
    "   $$\n",
    "\n",
    "5. **Softmax**:\n",
    "   $$\n",
    "   \\mathbf{probs}_{i,j} = \\text{softmax}(\\text{logits}^{\\text{final}}_{i,j}) \\quad \\forall \\ i \\in [1, \\text{seq}], \\ j \\in [1, |\\Sigma|] \\\\\n",
    "   \\mathbf{probs}_{i,j} = \\frac{e^{\\text{logits}^{\\text{final}}_{i,j}}}{\\sum_{k=1}^{|\\Sigma|} e^{\\text{logits}^{\\text{final}}_{i,k}}}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfd8154d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:15.589365Z",
     "iopub.status.busy": "2025-02-04T15:22:15.589091Z",
     "iopub.status.idle": "2025-02-04T15:22:16.684659Z",
     "shell.execute_reply": "2025-02-04T15:22:16.683714Z"
    },
    "id": "KhLvuGw5UpOh",
    "papermill": {
     "duration": 1.117942,
     "end_time": "2025-02-04T15:22:16.686887",
     "exception": false,
     "start_time": "2025-02-04T15:22:15.568945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cfg = Config()\n",
    "model = DemoTransformer(model_cfg).to(device)\n",
    "model.load_state_dict(reference_gpt2.state_dict(), strict=False) # загружаем веса gpt2\n",
    "\n",
    "tokenizer = reference_gpt2.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e474a43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:16.727409Z",
     "iopub.status.busy": "2025-02-04T15:22:16.727116Z",
     "iopub.status.idle": "2025-02-04T15:22:16.741399Z",
     "shell.execute_reply": "2025-02-04T15:22:16.740358Z"
    },
    "id": "opp-1FmGWgGn",
    "papermill": {
     "duration": 0.036422,
     "end_time": "2025-02-04T15:22:16.743099",
     "exception": false,
     "start_time": "2025-02-04T15:22:16.706677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerSampler:\n",
    "\n",
    "    def __init__(self, model: DemoTransformer, tokenizer: GPT2TokenizerFast):\n",
    "        self.model = model\n",
    "        self.cfg = model.cfg\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    @t.inference_mode()\n",
    "    def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs):\n",
    "        '''\n",
    "        Возвращаем сгенерированную строку, включая промпт.\n",
    "        Генерация заканчивается после max_tokens_generated токенов или по генерации EOS.\n",
    "        \n",
    "        kwargs передаются в sample_next_token\n",
    "        '''\n",
    "        output_text = prompt\n",
    "        for _ in range(max_tokens_generated):\n",
    "            input_ids = self.tokenizer.encode(output_text, return_tensors=\"pt\").to(device)\n",
    "            logits = self.model(input_ids)\n",
    "            token = self.sample_next_token(input_ids.reshape(-1), logits[-1, -1], **kwargs)\n",
    "            if token == self.tokenizer.eos_token_id:\n",
    "                return output_text\n",
    "            output_text += self.tokenizer.decode(token)\n",
    "        return output_text\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_next_token(\n",
    "        input_ids: Int[Tensor, \"seq_len\"],\n",
    "        logits: Float[Tensor, \"d_vocab\"],\n",
    "        temperature=1.0,\n",
    "        top_k=0,\n",
    "        top_p=0.0,\n",
    "        frequency_penalty=0.0,\n",
    "        seed=None\n",
    "    ):\n",
    "        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
    "        assert temperature >= 0, \"Temperature should be non-negative\"\n",
    "        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
    "        assert 0 <= top_k, \"Top-k must be non-negative\"\n",
    "        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
    "\n",
    "        # Set random seeds for reproducibility\n",
    "        if seed is not None:\n",
    "            t.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Apply all the specialized sampling methods\n",
    "        if temperature == 0:\n",
    "            return TransformerSampler.greedy_search(logits)\n",
    "        elif temperature != 1.0:\n",
    "            logits = TransformerSampler.apply_temperature(logits, temperature)\n",
    "        if frequency_penalty != 0.0:\n",
    "            logits = TransformerSampler.apply_frequency_penalty(input_ids, logits, frequency_penalty)\n",
    "        if top_k > 0:\n",
    "            return TransformerSampler.sample_top_k(logits, top_k)\n",
    "        if top_p > 0.0:\n",
    "            return TransformerSampler.sample_top_p(logits, top_p)\n",
    "        return TransformerSampler.sample_basic(logits)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def greedy_search(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
    "        '''\n",
    "        Возвращаем самый вероятный токен жадно\n",
    "        '''\n",
    "        out = logits.argmax().item()\n",
    "        return out\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_temperature(logits: Float[Tensor, \"d_vocab\"], temperature: float) -> Float[Tensor, \"d_vocab\"]:\n",
    "        '''\n",
    "        Применяем температуру к логитам\n",
    "        '''\n",
    "        return logits / temperature\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_frequency_penalty(input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float) -> Float[Tensor, \"d_vocab\"]:\n",
    "        '''\n",
    "        Применяем frequency penalty к логитам\n",
    "        '''\n",
    "        unique_tokens, counts = input_ids.unique(return_counts=True)\n",
    "        token_frequencies = dict(zip(unique_tokens.tolist(), counts.tolist()))\n",
    "\n",
    "        penalty = t.zeros_like(logits)\n",
    "        for token, freq in token_frequencies.items():\n",
    "            penalty[token] += freq_penalty * freq\n",
    "\n",
    "        logits_prime = logits - penalty\n",
    "\n",
    "        return logits_prime\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
    "        '''\n",
    "        Простое сэмплирование! Тут нам поможет torch.multinomial\n",
    "        '''\n",
    "        return t.multinomial(nn.functional.softmax(logits, dim=-1), 1).item()\n",
    "        \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n",
    "        '''\n",
    "        top-k сэмплирование\n",
    "        '''\n",
    "        top_k_values, top_k_indices = t.topk(logits, k)\n",
    "        mask = t.full_like(logits, float('-inf'))\n",
    "        mask.scatter_(0, top_k_indices, top_k_values) # тут k оригинальных логитов, а все остальное -inf\n",
    "\n",
    "        return t.multinomial(nn.functional.softmax(mask, dim=-1), 1).item()\n",
    "        \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sample_top_p(logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1) -> int:\n",
    "        '''\n",
    "        top_p сэмплирование\n",
    "        '''\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        sorted_probs, indices = t.sort(probs, descending=True)\n",
    "        cum_probs = t.cumsum(sorted_probs, dim=-1)\n",
    "        cutoff_index = max(t.searchsorted(cum_probs, top_p).item(), min_tokens_to_keep - 1)\n",
    "        mask = t.full_like(probs, float('-inf'))\n",
    "        mask.scatter_(0, indices[:cutoff_index + 1], logits[indices[:cutoff_index + 1]])\n",
    "\n",
    "        return t.multinomial(nn.functional.softmax(mask, dim=-1), 1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76fa74a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:16.782274Z",
     "iopub.status.busy": "2025-02-04T15:22:16.781898Z",
     "iopub.status.idle": "2025-02-04T15:22:17.767693Z",
     "shell.execute_reply": "2025-02-04T15:22:17.766825Z"
    },
    "id": "Tear0Nn0WjZY",
    "outputId": "5b8e4387-ebab-4159-9c98-422b949398d7",
    "papermill": {
     "duration": 1.007175,
     "end_time": "2025-02-04T15:22:17.769164",
     "exception": false,
     "start_time": "2025-02-04T15:22:16.761989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding with prompt: 'Jingle bells, jingle bells, jingle all the way'\n",
      "\n",
      "Your model said: 'Jingle bells, jingle bells, jingle all the way up to the top of the mountain.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = TransformerSampler(model, tokenizer)\n",
    "\n",
    "prompt = \"Jingle bells, jingle bells, jingle all the way\"\n",
    "print(f\"Greedy decoding with prompt: {prompt!r}\\n\")\n",
    "\n",
    "output = sampler.sample(prompt, max_tokens_generated=8, temperature=0.0)\n",
    "print(f\"Your model said: {output!r}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9387f40b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:17.806382Z",
     "iopub.status.busy": "2025-02-04T15:22:17.806037Z",
     "iopub.status.idle": "2025-02-04T15:22:17.811222Z",
     "shell.execute_reply": "2025-02-04T15:22:17.810053Z"
    },
    "papermill": {
     "duration": 0.02544,
     "end_time": "2025-02-04T15:22:17.812613",
     "exception": false,
     "start_time": "2025-02-04T15:22:17.787173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "expected = \"Jingle bells, jingle bells, jingle all the way up to the top of the mountain.\"\n",
    "assert output == expected\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc2870b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:17.850208Z",
     "iopub.status.busy": "2025-02-04T15:22:17.849925Z",
     "iopub.status.idle": "2025-02-04T15:22:17.866354Z",
     "shell.execute_reply": "2025-02-04T15:22:17.865220Z"
    },
    "id": "E3VYdChTdNLc",
    "outputId": "f39d0a54-e575-499a-c6bd-2998202246ee",
    "papermill": {
     "duration": 0.037228,
     "end_time": "2025-02-04T15:22:17.867864",
     "exception": false,
     "start_time": "2025-02-04T15:22:17.830636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A low temperature \"sharpens\" or \"peaks\" the distribution:  tensor([  0.0000, 693.1472])\n",
      "A high temperature flattens the distribution:  tensor([0.0000, 0.0007])\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "logits = t.tensor([1, 2]).log()\n",
    "\n",
    "cold_logits = TransformerSampler.apply_temperature(logits, temperature=0.001)\n",
    "print('A low temperature \"sharpens\" or \"peaks\" the distribution: ', cold_logits)\n",
    "t.testing.assert_close(cold_logits, 1000.0 * logits)\n",
    "\n",
    "hot_logits = TransformerSampler.apply_temperature(logits, temperature=1000.0)\n",
    "print(\"A high temperature flattens the distribution: \", hot_logits)\n",
    "t.testing.assert_close(hot_logits, 0.001 * logits)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0472dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:17.906039Z",
     "iopub.status.busy": "2025-02-04T15:22:17.905690Z",
     "iopub.status.idle": "2025-02-04T15:22:17.923165Z",
     "shell.execute_reply": "2025-02-04T15:22:17.922233Z"
    },
    "id": "J0no5kj-dTos",
    "outputId": "afcb8c9c-ddf4-4475-b9b9-1381c8d6e56a",
    "papermill": {
     "duration": 0.038005,
     "end_time": "2025-02-04T15:22:17.924395",
     "exception": false,
     "start_time": "2025-02-04T15:22:17.886390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "bieber_prompt = \"And I was like Baby, baby, baby, oh Like, Baby, baby, baby, no Like, Baby, baby, baby, oh I thought you'd always be mine, mine\"\n",
    "input_ids = tokenizer.encode(bieber_prompt, return_tensors=\"pt\")\n",
    "logits = t.ones(tokenizer.vocab_size)\n",
    "penalized_logits = TransformerSampler.apply_frequency_penalty(input_ids.squeeze(), logits, 2.0)\n",
    "\n",
    "assert penalized_logits[5156].item() == -11, \"Expected 6 occurrences of ' baby' with leading space, 1-2*6=-11\"\n",
    "assert penalized_logits[14801].item() == -5, \"Expected 3 occurrences of ' Baby' with leading space, 1-2*3=-5\"\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8a3d8f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T15:22:17.963163Z",
     "iopub.status.busy": "2025-02-04T15:22:17.962886Z",
     "iopub.status.idle": "2025-02-04T15:23:09.612034Z",
     "shell.execute_reply": "2025-02-04T15:23:09.610177Z"
    },
    "id": "AjQi5zDMWtTJ",
    "outputId": "65ed6a4a-e13f-44b7-8516-4b0c9b5dda33",
    "papermill": {
     "duration": 51.670856,
     "end_time": "2025-02-04T15:23:09.613911",
     "exception": false,
     "start_time": "2025-02-04T15:22:17.943055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e3ae6e6e264436969088599130309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ' church'. Expected freq 0.6384, observed freq 0.6308\n",
      "Word: ' house' . Expected freq 0.3616, observed freq 0.3692\n"
     ]
    }
   ],
   "source": [
    "prompt = \"John and Mary went to the\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "logits = model(input_ids)[0, -1]\n",
    "\n",
    "expected_top_10pct = {\n",
    "    \" church\": 0.0648,\n",
    "    \" house\": 0.0367, # These are the two most likely tokens, and add up to >10%\n",
    "}\n",
    "top_10pct_sum = sum(expected_top_10pct.values())\n",
    "\n",
    "observed_freqs = defaultdict(int)\n",
    "\n",
    "N = 10000\n",
    "for _ in tqdm(range(N)):\n",
    "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_p=0.1)\n",
    "    observed_freqs[tokenizer.decode(token)] += 1\n",
    "\n",
    "for word in expected_top_10pct:\n",
    "    expected_freq = expected_top_10pct[word] / top_10pct_sum\n",
    "    observed_freq = observed_freqs[word] / N\n",
    "    print(f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\")\n",
    "    assert abs(observed_freq - expected_freq) < 0.01, \"Try increasing N if this fails by a small amount.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb5cc7",
   "metadata": {
    "papermill": {
     "duration": 0.01822,
     "end_time": "2025-02-04T15:23:09.651470",
     "exception": false,
     "start_time": "2025-02-04T15:23:09.633250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Оно закончилось"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xnqvoOGqZ2oX"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.135877,
   "end_time": "2025-02-04T15:23:13.293471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-04T15:20:31.157594",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "034be27ccc0c4ec799345c3e5c6fc5de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0687438c47da46cba70d4ec5d03088cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d76f1e95e734f9195274efa982d3a79",
        "IPY_MODEL_eaaae65aa8f14c5aa88542e280dd48cb",
        "IPY_MODEL_ebab4517baff494c9e3337c409f2e869"
       ],
       "layout": "IPY_MODEL_0b7f0ff2d97c446d99b52cd06d4bcb96",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0719d19237d24c88a4afd5ed45b3477b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "086eefa394d9428c962ee51275dcd173": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a09caa6b76f4d65aa5efdadf9916e41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_49c5c043c59243f495c201870073a326",
       "max": 26.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_34cc199e4a9340c9ab4485ab6d359d12",
       "tabbable": null,
       "tooltip": null,
       "value": 26.0
      }
     },
     "0b7f0ff2d97c446d99b52cd06d4bcb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c3f78ddba2e4f6fba3dd4e9e41196a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "13139be3fcab4ec4b1b33eb435842dfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eab9c48c7b6140d59f2142192b042813",
       "placeholder": "​",
       "style": "IPY_MODEL_c1f546939f9b467ea0224fb0229ef81e",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "14b71c265e074a7d8fda01833f51d3fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "155eb47319944be4ab1bb4c82da875ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1660b54486a849cc9dd63911a6d17fa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_155eb47319944be4ab1bb4c82da875ce",
       "max": 124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_68fe8fd70f6a44278cf8839d87a4a917",
       "tabbable": null,
       "tooltip": null,
       "value": 124.0
      }
     },
     "177682ff14d74807970e15a5a90e3559": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1bc43053ad1f49b3bd3d793b5a826b0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2156f87f9f36462f8ad9fbd5373dbf51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21e3ae6e6e264436969088599130309f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_13139be3fcab4ec4b1b33eb435842dfe",
        "IPY_MODEL_98387d6e1c5e42ed897141c6311ee24c",
        "IPY_MODEL_e916c68b11ec4cf2a342367d7545db70"
       ],
       "layout": "IPY_MODEL_adf8b94c48b049038c26a77e15f066d5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "27ffd6809f0a43439e24403d63081fde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6ff0b477760d47ec9505200265ac8ea1",
       "max": 548105171.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_69348abde92e40ae8c05c1155a581aad",
       "tabbable": null,
       "tooltip": null,
       "value": 548105171.0
      }
     },
     "292818f8ccf24b92ab4c7f258ec897eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b9703acbc3c4d5da6757594ef8acf25",
       "placeholder": "​",
       "style": "IPY_MODEL_f0eaad359b0842ebb5f95f515a86aa73",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "29586640736e4098af3eb1e32b9f8d68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2abcf54dd2cd444888d7aa90e915587c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b14a5ae87e647e3ae73f0575cdc8fdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab897bfd25d0400ba4d3980fabe59054",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e00d26df88f74f99aa66284b5a456915",
       "tabbable": null,
       "tooltip": null,
       "value": 456318.0
      }
     },
     "2b9703acbc3c4d5da6757594ef8acf25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ca39ecdeda2475b881053e093283044": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_292818f8ccf24b92ab4c7f258ec897eb",
        "IPY_MODEL_53b9c3163a9f45b8a3d7646e32e4fbd2",
        "IPY_MODEL_acd9af5e8b2e4e3b8dee0bffb3417c39"
       ],
       "layout": "IPY_MODEL_a9818f98d5624a01a183c4cdcc6ef48b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2d76f1e95e734f9195274efa982d3a79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d2a81c74f5194abb999b2b7a37948e28",
       "placeholder": "​",
       "style": "IPY_MODEL_c6f3ac61b0224fb5ae875d035a0d1913",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: 100%"
      }
     },
     "2da3667aecea403680a15f862b8e24dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "313f4631be8749d282ca5d74c0c62803": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bee345c2597b41c1b5dc4f14361ac298",
       "placeholder": "​",
       "style": "IPY_MODEL_fe4dd01dadc040e3b6773c3f8b5439e8",
       "tabbable": null,
       "tooltip": null,
       "value": " 548M/548M [00:02&lt;00:00, 248MB/s]"
      }
     },
     "34cc199e4a9340c9ab4485ab6d359d12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "393835be89ab4983927f96a3d012738f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b99a4ca1648445fb9d7980a6ff96dfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3dd5fc2969ba4f58ad7302cf7b2e13a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d343cd7c48ce4ece838d9cddc8bc8ec4",
       "placeholder": "​",
       "style": "IPY_MODEL_79b8569310104d35887cd9ed8cb651aa",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "426b11cb065e41cbb90d6bf2f189ed60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "428ea7df28a1426e81532def845d23e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4844d0a77a944b92827ce78e0ef17fa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "49c5c043c59243f495c201870073a326": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e1a98d408074fc4b0d19a0cca182c60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b01bab2a723414ca0db6ccdd3319828",
        "IPY_MODEL_1660b54486a849cc9dd63911a6d17fa0",
        "IPY_MODEL_8f6c133231114fc0893df0e933629597"
       ],
       "layout": "IPY_MODEL_1bc43053ad1f49b3bd3d793b5a826b0d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "52267ba9decb4ae6a9eb21bb9391758b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a3f1167ad8754113b55b71ff9b67cdb4",
        "IPY_MODEL_2b14a5ae87e647e3ae73f0575cdc8fdd",
        "IPY_MODEL_81022d7cddd74273b73a33ac71344f1c"
       ],
       "layout": "IPY_MODEL_426b11cb065e41cbb90d6bf2f189ed60",
       "tabbable": null,
       "tooltip": null
      }
     },
     "53b9c3163a9f45b8a3d7646e32e4fbd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_795018daaf92481ba3e742e4303d1093",
       "max": 665.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_428ea7df28a1426e81532def845d23e8",
       "tabbable": null,
       "tooltip": null,
       "value": 665.0
      }
     },
     "59f7540aff954408aba89bd0bef979df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6187f90cadb94417a2222807faf84794": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afec9d44fc314b75ae8390184489ee0a",
        "IPY_MODEL_0a09caa6b76f4d65aa5efdadf9916e41",
        "IPY_MODEL_99f6ac007a654c2d88ad1ea5899a01b8"
       ],
       "layout": "IPY_MODEL_77dd464f43be4e52ba8237c55d808d37",
       "tabbable": null,
       "tooltip": null
      }
     },
     "68fe8fd70f6a44278cf8839d87a4a917": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "69348abde92e40ae8c05c1155a581aad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6aa8839e6fd04f35bcbb908a7df341fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6b01bab2a723414ca0db6ccdd3319828": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_393835be89ab4983927f96a3d012738f",
       "placeholder": "​",
       "style": "IPY_MODEL_0719d19237d24c88a4afd5ed45b3477b",
       "tabbable": null,
       "tooltip": null,
       "value": "generation_config.json: 100%"
      }
     },
     "6ff0b477760d47ec9505200265ac8ea1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "75fbb2572cb244b8a284069adc9b12db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "77dd464f43be4e52ba8237c55d808d37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "795018daaf92481ba3e742e4303d1093": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "79b8569310104d35887cd9ed8cb651aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "80476382b6944116862f12ae7c6f3e2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81022d7cddd74273b73a33ac71344f1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2156f87f9f36462f8ad9fbd5373dbf51",
       "placeholder": "​",
       "style": "IPY_MODEL_177682ff14d74807970e15a5a90e3559",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/456k [00:00&lt;00:00, 1.27MB/s]"
      }
     },
     "84c443e2d317489d8c71a5c032bd1683": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "86c2f8559a51471e8076041f26778198": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "891fd11ee66e4cb0b893f552ba60244c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b0daf0f9fd24191bde3a7089759bc3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8e5506d2690e4e3593debb73d91a596c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f6c133231114fc0893df0e933629597": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84c443e2d317489d8c71a5c032bd1683",
       "placeholder": "​",
       "style": "IPY_MODEL_969d77f17dd84c2baa261e54253115e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 124/124 [00:00&lt;00:00, 13.9kB/s]"
      }
     },
     "90f924aac56c4daa8c03f51dc1ed85c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "921a811d83ba4c20b73e266f4c5aa1e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e68ed11b2bbd4cb3b6d3543a7717ec65",
       "placeholder": "​",
       "style": "IPY_MODEL_3b99a4ca1648445fb9d7980a6ff96dfe",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.36M/1.36M [00:00&lt;00:00, 7.16MB/s]"
      }
     },
     "969d77f17dd84c2baa261e54253115e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98387d6e1c5e42ed897141c6311ee24c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_29586640736e4098af3eb1e32b9f8d68",
       "max": 10000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_14b71c265e074a7d8fda01833f51d3fc",
       "tabbable": null,
       "tooltip": null,
       "value": 10000.0
      }
     },
     "9896161718494613a4da49e8d4677fa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_891fd11ee66e4cb0b893f552ba60244c",
       "max": 1355256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab14fae3b6094e5a9f1aaeb96ce0e397",
       "tabbable": null,
       "tooltip": null,
       "value": 1355256.0
      }
     },
     "996c05275dc1451f9bd81695a213af81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3dd5fc2969ba4f58ad7302cf7b2e13a3",
        "IPY_MODEL_27ffd6809f0a43439e24403d63081fde",
        "IPY_MODEL_313f4631be8749d282ca5d74c0c62803"
       ],
       "layout": "IPY_MODEL_80476382b6944116862f12ae7c6f3e2e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "99f6ac007a654c2d88ad1ea5899a01b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2da3667aecea403680a15f862b8e24dd",
       "placeholder": "​",
       "style": "IPY_MODEL_75fbb2572cb244b8a284069adc9b12db",
       "tabbable": null,
       "tooltip": null,
       "value": " 26.0/26.0 [00:00&lt;00:00, 3.03kB/s]"
      }
     },
     "9b26085e8e2f4c87bb5d1dff41989f1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d42132079d9e42bab5397786401f3e26",
       "placeholder": "​",
       "style": "IPY_MODEL_6aa8839e6fd04f35bcbb908a7df341fb",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "9d1119dd5c6a4cf697cdd88b4289446a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a3f1167ad8754113b55b71ff9b67cdb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc01652fa97d4b96941a693453b36299",
       "placeholder": "​",
       "style": "IPY_MODEL_f56734958a2a40cba3278ba872c057ad",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: 100%"
      }
     },
     "a4cd207fb58f4606b49fbd172c25255b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9818f98d5624a01a183c4cdcc6ef48b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab14fae3b6094e5a9f1aaeb96ce0e397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab897bfd25d0400ba4d3980fabe59054": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acd9af5e8b2e4e3b8dee0bffb3417c39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_efaf705b1b9b4b3e8827a57b53c06dd6",
       "placeholder": "​",
       "style": "IPY_MODEL_fbc7190b018e41c19d10187805e09d2e",
       "tabbable": null,
       "tooltip": null,
       "value": " 665/665 [00:00&lt;00:00, 66.8kB/s]"
      }
     },
     "adf8b94c48b049038c26a77e15f066d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aeb45308141148c8ae4deb5443ed58f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7288bd40d5d4399b0ddce1b4686d9a3",
        "IPY_MODEL_d36fc05c2e6e4983888a6b1fba5e872a",
        "IPY_MODEL_d1c08773b13e4ce595726e546abc9682"
       ],
       "layout": "IPY_MODEL_c9e3ba9e19454306836bb388cb2a91e7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afec9d44fc314b75ae8390184489ee0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2abcf54dd2cd444888d7aa90e915587c",
       "placeholder": "​",
       "style": "IPY_MODEL_8b0daf0f9fd24191bde3a7089759bc3e",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "b7288bd40d5d4399b0ddce1b4686d9a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59f7540aff954408aba89bd0bef979df",
       "placeholder": "​",
       "style": "IPY_MODEL_90f924aac56c4daa8c03f51dc1ed85c0",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "bc01652fa97d4b96941a693453b36299": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bee345c2597b41c1b5dc4f14361ac298": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1f546939f9b467ea0224fb0229ef81e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c6f3ac61b0224fb5ae875d035a0d1913": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c9e3ba9e19454306836bb388cb2a91e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1c08773b13e4ce595726e546abc9682": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dedfa353e921480ba59119bd723d8581",
       "placeholder": "​",
       "style": "IPY_MODEL_0c3f78ddba2e4f6fba3dd4e9e41196a7",
       "tabbable": null,
       "tooltip": null,
       "value": " 100/100 [00:23&lt;00:00,  2.90it/s]"
      }
     },
     "d2a81c74f5194abb999b2b7a37948e28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d343cd7c48ce4ece838d9cddc8bc8ec4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d36fc05c2e6e4983888a6b1fba5e872a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a4cd207fb58f4606b49fbd172c25255b",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4844d0a77a944b92827ce78e0ef17fa3",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "d42132079d9e42bab5397786401f3e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dedfa353e921480ba59119bd723d8581": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e00d26df88f74f99aa66284b5a456915": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e415b295c4294358889c9c1191a64b3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e68ed11b2bbd4cb3b6d3543a7717ec65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e916c68b11ec4cf2a342367d7545db70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e415b295c4294358889c9c1191a64b3e",
       "placeholder": "​",
       "style": "IPY_MODEL_9d1119dd5c6a4cf697cdd88b4289446a",
       "tabbable": null,
       "tooltip": null,
       "value": " 10000/10000 [00:51&lt;00:00, 193.50it/s]"
      }
     },
     "ea30c88dd5854a4c8e52ec6b22d45af1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9b26085e8e2f4c87bb5d1dff41989f1d",
        "IPY_MODEL_9896161718494613a4da49e8d4677fa0",
        "IPY_MODEL_921a811d83ba4c20b73e266f4c5aa1e9"
       ],
       "layout": "IPY_MODEL_034be27ccc0c4ec799345c3e5c6fc5de",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eaaae65aa8f14c5aa88542e280dd48cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_86c2f8559a51471e8076041f26778198",
       "max": 1042301.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5d15106f6b742ccb5f2ebc83d1e5e44",
       "tabbable": null,
       "tooltip": null,
       "value": 1042301.0
      }
     },
     "eab9c48c7b6140d59f2142192b042813": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebab4517baff494c9e3337c409f2e869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_086eefa394d9428c962ee51275dcd173",
       "placeholder": "​",
       "style": "IPY_MODEL_8e5506d2690e4e3593debb73d91a596c",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.04M/1.04M [00:00&lt;00:00, 2.92MB/s]"
      }
     },
     "efaf705b1b9b4b3e8827a57b53c06dd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0eaad359b0842ebb5f95f515a86aa73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f56734958a2a40cba3278ba872c057ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f5d15106f6b742ccb5f2ebc83d1e5e44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fbc7190b018e41c19d10187805e09d2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe4dd01dadc040e3b6773c3f8b5439e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
